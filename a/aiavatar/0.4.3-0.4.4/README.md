# Comparing `tmp/aiavatar-0.4.3-py3-none-any.whl.zip` & `tmp/aiavatar-0.4.4-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,25 +1,25 @@
-Zip file size: 24850 bytes, number of entries: 23
+Zip file size: 25527 bytes, number of entries: 23
 -rw-r--r--  2.0 unx      438 b- defN 24-Feb-26 03:37 aiavatar/__init__.py
 -rw-r--r--  2.0 unx     3407 b- defN 24-Apr-07 17:32 aiavatar/avatar.py
--rw-r--r--  2.0 unx     6092 b- defN 24-Apr-11 11:17 aiavatar/bot.py
+-rw-r--r--  2.0 unx     6841 b- defN 24-Apr-13 11:34 aiavatar/bot.py
 -rw-r--r--  2.0 unx     1771 b- defN 24-Apr-07 09:53 aiavatar/animation/__init__.py
--rw-r--r--  2.0 unx     1448 b- defN 24-Apr-12 03:02 aiavatar/animation/vrchat.py
+-rw-r--r--  2.0 unx     1448 b- defN 24-Apr-12 20:35 aiavatar/animation/vrchat.py
 -rw-r--r--  2.0 unx       31 b- defN 23-May-27 03:48 aiavatar/device/__init__.py
 -rw-r--r--  2.0 unx     2344 b- defN 24-Apr-11 11:13 aiavatar/device/audio.py
 -rw-r--r--  2.0 unx     1650 b- defN 23-Jun-04 16:30 aiavatar/face/__init__.py
 -rw-r--r--  2.0 unx     1556 b- defN 23-Jun-04 16:30 aiavatar/face/vrchat.py
--rw-r--r--  2.0 unx     6342 b- defN 24-Apr-07 07:28 aiavatar/listeners/__init__.py
--rw-r--r--  2.0 unx     1892 b- defN 24-Feb-26 00:03 aiavatar/listeners/azurevoicerequest.py
--rw-r--r--  2.0 unx     2085 b- defN 24-Feb-26 03:54 aiavatar/listeners/azurewakeword.py
+-rw-r--r--  2.0 unx     6342 b- defN 24-Apr-13 08:25 aiavatar/listeners/__init__.py
+-rw-r--r--  2.0 unx     2522 b- defN 24-Apr-13 08:55 aiavatar/listeners/azurevoicerequest.py
+-rw-r--r--  2.0 unx     2849 b- defN 24-Apr-13 10:44 aiavatar/listeners/azurewakeword.py
 -rw-r--r--  2.0 unx      977 b- defN 24-Feb-26 00:10 aiavatar/listeners/voicerequest.py
 -rw-r--r--  2.0 unx     1078 b- defN 24-Feb-26 03:54 aiavatar/listeners/wakeword.py
 -rw-r--r--  2.0 unx      178 b- defN 23-May-27 08:55 aiavatar/processors/__init__.py
--rw-r--r--  2.0 unx     5484 b- defN 24-Feb-24 06:51 aiavatar/processors/chatgpt.py
+-rw-r--r--  2.0 unx     6162 b- defN 24-Apr-13 01:31 aiavatar/processors/chatgpt.py
 -rw-r--r--  2.0 unx      275 b- defN 24-Apr-12 01:48 aiavatar/speech/__init__.py
 -rw-r--r--  2.0 unx     2483 b- defN 24-Apr-12 01:48 aiavatar/speech/voicevox.py
--rw-r--r--  2.0 unx    11324 b- defN 24-Apr-12 03:02 aiavatar-0.4.3.dist-info/LICENSE
--rw-r--r--  2.0 unx    12628 b- defN 24-Apr-12 03:02 aiavatar-0.4.3.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 24-Apr-12 03:02 aiavatar-0.4.3.dist-info/WHEEL
--rw-r--r--  2.0 unx        9 b- defN 24-Apr-12 03:02 aiavatar-0.4.3.dist-info/top_level.txt
--rw-rw-r--  2.0 unx     1905 b- defN 24-Apr-12 03:02 aiavatar-0.4.3.dist-info/RECORD
-23 files, 65489 bytes uncompressed, 21766 bytes compressed:  66.8%
+-rw-r--r--  2.0 unx    11324 b- defN 24-Apr-13 11:36 aiavatar-0.4.4.dist-info/LICENSE
+-rw-r--r--  2.0 unx    12628 b- defN 24-Apr-13 11:36 aiavatar-0.4.4.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 24-Apr-13 11:36 aiavatar-0.4.4.dist-info/WHEEL
+-rw-r--r--  2.0 unx        9 b- defN 24-Apr-13 11:36 aiavatar-0.4.4.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx     1905 b- defN 24-Apr-13 11:36 aiavatar-0.4.4.dist-info/RECORD
+23 files, 68310 bytes uncompressed, 22443 bytes compressed:  67.1%
```

## zipnote {}

```diff
@@ -48,23 +48,23 @@
 
 Filename: aiavatar/speech/__init__.py
 Comment: 
 
 Filename: aiavatar/speech/voicevox.py
 Comment: 
 
-Filename: aiavatar-0.4.3.dist-info/LICENSE
+Filename: aiavatar-0.4.4.dist-info/LICENSE
 Comment: 
 
-Filename: aiavatar-0.4.3.dist-info/METADATA
+Filename: aiavatar-0.4.4.dist-info/METADATA
 Comment: 
 
-Filename: aiavatar-0.4.3.dist-info/WHEEL
+Filename: aiavatar-0.4.4.dist-info/WHEEL
 Comment: 
 
-Filename: aiavatar-0.4.3.dist-info/top_level.txt
+Filename: aiavatar-0.4.4.dist-info/top_level.txt
 Comment: 
 
-Filename: aiavatar-0.4.3.dist-info/RECORD
+Filename: aiavatar-0.4.4.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## aiavatar/bot.py

```diff
@@ -36,14 +36,15 @@
         output_device: int=-1,
         # Avatar
         animation_controller: AnimationController=None,
         face_controller: FaceController=None,
         avatar_request_parser: Callable=None,
         # Chat
         start_voice: str="どうしたの",
+        split_chars: list=None
     ):
 
         self.logger = getLogger(__name__)
         self.logger.addHandler(NullHandler())
 
         # Audio Devices
         if isinstance(input_device, int):
@@ -94,53 +95,72 @@
         animation_controller = animation_controller or AnimationControllerDummy()
         face_controller = face_controller or FaceControllerDummy()
         self.avatar_controller = AvatarController(speech_controller, animation_controller, face_controller, avatar_request_parser)
 
         # Chat
         self.chat_task = None
         self.start_voice = start_voice
+        self.split_chars = split_chars or ["。", "、", "？", "！", ".", ",", "?", "!"]
+
+        self.on_turn_end = self.on_turn_end_default
+
+    async def on_turn_end_default(self, request_text: str, response_text: str) -> bool:
+        return False
 
     async def chat(self, request_on_start: str=None, skip_start_voice: bool=False):
         if not skip_start_voice:
             try:
                 await self.avatar_controller.speech_controller.speak(self.start_voice)
             except Exception as ex:
                 self.logger.error(f"Error at starting chat: {str(ex)}\n{traceback.format_exc()}")
 
         while True:
+            request_text = ""
+            response_text = ""
             try:
                 if request_on_start:
-                    req = request_on_start
+                    request_text = request_on_start
                     request_on_start = None
                 else:
-                    req = await self.request_listener.get_request()
-                    if not req:
+                    request_text = await self.request_listener.get_request()
+                    if not request_text:
                         break
 
-                self.logger.info(f"User: {req}")
+                self.logger.info(f"User: {request_text}")
                 self.logger.info("AI:")
 
                 avatar_task = asyncio.create_task(self.avatar_controller.start())
 
                 stream_buffer = ""
-                async for t in self.chat_processor.chat(req):
+                async for t in self.chat_processor.chat(request_text):
                     stream_buffer += t
-                    sp = stream_buffer.replace("。", "。|").replace("、", "、|").replace("！", "！|").replace("？", "？|").split("|")
+                    for spc in self.split_chars:
+                        stream_buffer = stream_buffer.replace(spc, spc + "|")
+                    sp = stream_buffer.split("|")
                     if len(sp) > 1: # >1 means `|` is found (splited at the end of sentence)
                         sentence = sp.pop(0)
                         stream_buffer = "".join(sp)
                         self.avatar_controller.set_text(sentence)
+                        response_text += sentence
                     await asyncio.sleep(0.01)   # wait slightly in every loop not to use up CPU
 
+                if stream_buffer:
+                    self.avatar_controller.set_text(stream_buffer)
+                    response_text += stream_buffer
+
                 self.avatar_controller.set_stop()
                 await avatar_task
             
             except Exception as ex:
                 self.logger.error(f"Error at chatting loop: {str(ex)}\n{traceback.format_exc()}")
 
+            finally:
+                if await self.on_turn_end(request_text, response_text):
+                    break
+
     async def start_chat(self, request_on_start: str=None, skip_start_voice: bool=False):
         self.stop_chat()
         self.chat_task = asyncio.create_task(self.chat(request_on_start, skip_start_voice))
         await self.chat_task
 
     def stop_chat(self):
         if self.chat_task is not None:
```

## aiavatar/listeners/azurevoicerequest.py

```diff
@@ -1,39 +1,50 @@
 # pip install azure-cognitiveservices-speech
+import asyncio
 from logging import getLogger, NullHandler
+import time
 import azure.cognitiveservices.speech as speechsdk
 from azure.cognitiveservices.speech import PropertyId
 from . import RequestListenerBase
 
 class AzureVoiceRequestListener(RequestListenerBase):
     def __init__(self, api_key: str, region: str, timeout: float=0.5, detection_timeout: float=10.0, lang: str="ja-JP", device_name: str=None):
         self.logger = getLogger(__name__)
         self.logger.addHandler(NullHandler())
 
+        self.detection_timeout = detection_timeout
         self.speech_config = speechsdk.SpeechConfig(subscription=api_key, region=region)
         self.speech_config.set_property(PropertyId.SpeechServiceConnection_InitialSilenceTimeoutMs, str(detection_timeout * 1000))
         self.speech_config.set_property(PropertyId.Speech_SegmentationSilenceTimeoutMs, str(timeout * 1000))
 
         if device_name:
             # NOTE: You can see the way to check the device_name at Microsoft Learn.
             # https://learn.microsoft.com/ja-jp/azure/ai-services/speech-service/how-to-select-audio-input-devices
             self.audio_config = speechsdk.AudioConfig(device_name=device_name)
         else:
             self.audio_config = speechsdk.AudioConfig(use_default_microphone=True)
 
         self.speech_recognizer = speechsdk.SpeechRecognizer(speech_config=self.speech_config, audio_config=self.audio_config, language=lang)
+        self.recognizer_wait_time = 0.3
 
         self.on_start_listening = None
 
     async def get_request(self):
         if self.on_start_listening:
             await self.on_start_listening()
 
         self.logger.info(f"Listening... ({self.__class__.__name__})")
-        result = self.speech_recognizer.recognize_once()
 
-        if result.text:
-            self.logger.info(f"AzureVoiceRequestListener: {result.text}")
-        else:
-            self.logger.info(f"AzureVoiceRequestListener: No speech recognized.")
-
-        return result.text
+        start_at = time.time()
+        while True:
+            result = self.speech_recognizer.recognize_once()
+            if result.text:
+                self.logger.info(f"AzureVoiceRequestListener: {result.text}")
+                return result.text
+            else:
+                elapsed = time.time() - start_at
+                if elapsed < self.detection_timeout:
+                    self.logger.info(f"AzureVoiceRequestListener: Noise detected. Retrying... (elapsed: {elapsed})")
+                    await asyncio.sleep(self.recognizer_wait_time)    # Wait a bit before calling recognize_once() again. 0.2 was too short on my environment.
+                else:
+                    self.logger.info(f"AzureVoiceRequestListener: No speech recognized.")
+                    return ""
```

## aiavatar/listeners/azurewakeword.py

```diff
@@ -1,11 +1,13 @@
 # pip install azure-cognitiveservices-speech
 import asyncio
 from logging import getLogger, NullHandler
+import queue
 from threading import Thread
+import traceback
 from typing import Callable
 import azure.cognitiveservices.speech as speechsdk
 
 class AzureWakewordListener:
     def __init__(self, api_key: str, region: str, wakewords: list, on_wakeword: Callable, lang: str="ja-JP", device_name: str=None, verbose: bool=False):
         self.logger = getLogger(__name__)
         self.logger.addHandler(NullHandler())
@@ -16,32 +18,51 @@
             # NOTE: You can see the way to check the device_name at Microsoft Learn.
             # https://learn.microsoft.com/ja-jp/azure/ai-services/speech-service/how-to-select-audio-input-devices
             self.audio_config = speechsdk.AudioConfig(device_name=device_name)
         else:
             self.audio_config = speechsdk.AudioConfig(use_default_microphone=True)
 
         self.speech_recognizer = speechsdk.SpeechRecognizer(speech_config=self.speech_config, audio_config=self.audio_config, language=lang)
-        self.speech_recognizer.recognized.connect(lambda evt: self.on_recognized(evt))
 
         self.wakewords = wakewords
         self.on_wakeword = on_wakeword
+        self.recognized_queue = queue.Queue()
         self.verbose = verbose
     
     def on_recognized(self, evt):
         recognized_text = evt.result.text.replace("。", "").replace("、", "").replace("!", "").replace("！", "").replace("?", "").replace("？", "").strip()
 
         if self.verbose:
             self.logger.info(f"AzureWakeWordListener: {recognized_text}")
 
         if recognized_text in self.wakewords:
-            asyncio.run(self.on_wakeword(recognized_text))
+            self.recognized_queue.put_nowait(recognized_text)
 
-    async def start_listening(self):
+    async def on_wakeword_async(self, recognized_text: str):
+        await self.on_wakeword(recognized_text)
+
+    def enable_recognition(self):
         self.logger.info(f"Listening... ({self.__class__.__name__})")
+        self.speech_recognizer.recognized.connect(lambda evt: self.on_recognized(evt))
+    
+    def disable_recognition(self):
+        self.speech_recognizer.recognized.disconnect_all()
+
+    async def start_listening(self):
         self.speech_recognizer.start_continuous_recognition()
+        self.enable_recognition()
         while True:
-            await asyncio.sleep(0.1)
+            # Wait for queue
+            recognized_text = self.recognized_queue.get()
+            # Process recognized text
+            self.disable_recognition()
+            try:
+                await self.on_wakeword(recognized_text)
+            except Exception as ex:
+                self.logger.error(f"Error at on_wake: {ex}\n{traceback.format_exc()}")
+            self.recognized_queue.task_done()
+            self.enable_recognition()
 
     def start(self):
         th = Thread(target=asyncio.run, args=(self.start_listening(),), daemon=True)
         th.start()
         return th
```

## aiavatar/processors/chatgpt.py

```diff
@@ -1,8 +1,9 @@
 from logging import getLogger, NullHandler
+from datetime import datetime
 import traceback
 import json
 from typing import Iterator, Callable, AsyncGenerator
 from openai import AsyncClient
 from . import ChatProcessor
 
 class ChatGPTFunction:
@@ -27,34 +28,54 @@
 
     @property
     def response_type(self):
         return "function_call" if self.function_name else "content"
 
 
 class ChatGPTProcessor(ChatProcessor):
-    def __init__(self, api_key: str, model: str="gpt-3.5-turbo", temperature: float=1.0, max_tokens: int=0, functions: dict=None, system_message_content: str=None, history_count: int=10):
+    def __init__(self, api_key: str, model: str="gpt-3.5-turbo", temperature: float=1.0, max_tokens: int=0, functions: dict=None, system_message_content: str=None, history_count: int=10, history_timeout: float=60.0):
         self.logger = getLogger(__name__)
         self.logger.addHandler(NullHandler())
 
         self.api_key = api_key
         self.model = model
         self.temperature = temperature
         self.max_tokens = max_tokens
         self.functions = functions or {}
         self.system_message_content = system_message_content
         self.history_count = history_count
+        self.history_timeout = history_timeout
         self.histories = []
+        self.last_chat_at = datetime.utcnow()
         self.on_start_processing = None
 
     def add_function(self, name: str, description: str=None, parameters: dict=None, func: Callable=None):
         self.functions[name] = ChatGPTFunction(name=name, description=description, parameters=parameters, func=func)
 
     def reset_histories(self):
         self.histories.clear()
 
+    def build_messages(self, text):
+        messages = []
+        try:
+            # System message
+            if self.system_message_content:
+                messages.append({"role": "system", "content": self.system_message_content})
+
+            # Histories
+            messages.extend(self.histories[-1 * self.history_count:])
+
+            # Current user message
+            messages.append({"role": "user", "content": text})
+        
+        except Exception as ex:
+            self.logger.error(f"Error at build_messages: {ex}\n{traceback.format_exc()}")
+
+        return messages
+
     async def chat_completion_stream(self, async_client: AsyncClient, messages: list, call_functions: bool=True):
         params = {
             "messages": messages,
             "model": self.model,
             "temperature": self.temperature,
             "stream": True,
         }
@@ -75,22 +96,21 @@
         
         return stream_resp
 
     async def chat(self, text: str) -> AsyncGenerator[str, None]:
         try:
             async_client = AsyncClient(api_key=self.api_key)
 
+            if (datetime.utcnow() - self.last_chat_at).total_seconds() > self.history_timeout:
+                self.reset_histories()
+
             if self.on_start_processing:
                 await self.on_start_processing()
 
-            messages = []
-            if self.system_message_content:
-                messages.append({"role": "system", "content": self.system_message_content})
-            messages.extend(self.histories[-1 * self.history_count:])
-            messages.append({"role": "user", "content": text})
+            messages = self.build_messages(text)
 
             response_text = ""
             stream_resp = await self.chat_completion_stream(async_client, messages)
 
             async for chunk in stream_resp.stream:
                 delta = chunk.choices[0].delta
                 if stream_resp.response_type == "content":
@@ -135,9 +155,10 @@
                 self.histories.append({"role": "assistant", "content": response_text})
 
         except Exception as ex:
             self.logger.error(f"Error at chat: {str(ex)}\n{traceback.format_exc()}")
             raise ex
         
         finally:
+            self.last_chat_at = datetime.utcnow()
             if not async_client.is_closed():
                 await async_client.close()
```

## Comparing `aiavatar-0.4.3.dist-info/LICENSE` & `aiavatar-0.4.4.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `aiavatar-0.4.3.dist-info/METADATA` & `aiavatar-0.4.4.dist-info/METADATA`

 * *Files 0% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: aiavatar
-Version: 0.4.3
+Version: 0.4.4
 Summary: 🥰 Building AI-based conversational avatars lightning fast ⚡️💬
 Home-page: https://github.com/uezo/aiavatar
 Author: uezo
 Author-email: uezo@uezo.net
 Maintainer: uezo
 Maintainer-email: uezo@uezo.net
 License: Apache v2
```

## Comparing `aiavatar-0.4.3.dist-info/RECORD` & `aiavatar-0.4.4.dist-info/RECORD`

 * *Files 10% similar despite different names*

```diff
@@ -1,23 +1,23 @@
 aiavatar/__init__.py,sha256=Q7dfZ9PWg6btZmfXMbOYHfo7pUy2c6ja9c84t5HJECA,438
 aiavatar/avatar.py,sha256=ML4A_-cFggDOT4Sxb7VQMHvHD_rATxhY3Pt85ZppEKg,3407
-aiavatar/bot.py,sha256=H6HOQciv9YY_cWFZsCXOA2Ua8KMAQYCQ_pqVUs9iuUU,6092
+aiavatar/bot.py,sha256=F1lE5UAbfnv_IAqs7_-KgnVkgtKpu1Qjun8xKt0ChrY,6841
 aiavatar/animation/__init__.py,sha256=aaYbs5I7vnXPEq39sJ2h7v-sG1WqfyocH4iepDSqz08,1771
 aiavatar/animation/vrchat.py,sha256=8aD3o9_NHJCiINiI-tjxF6cGevmJtvZ9IWTsixDj1Vc,1448
 aiavatar/device/__init__.py,sha256=4DhskQxS20PcErkyF3z5-RuvXtGCQvw37jqB-yc2As8,31
 aiavatar/device/audio.py,sha256=xxRzbjyabXGrhY3WDc3UYEadjCU-xS7HF_vcXtGiC88,2344
 aiavatar/face/__init__.py,sha256=FPaP8RT8UXQ_UMON7RLvg2FUotOzTFVJ1qxzVk5zBTw,1650
 aiavatar/face/vrchat.py,sha256=VOibFm5Yuof-RQGfd1Zt1tx4v-TV9Usb8aMn7rHp5HY,1556
 aiavatar/listeners/__init__.py,sha256=-dLrr-HV2xdRaVgxv6tkohKSmHe9REKw4sriReRbv1Y,6342
-aiavatar/listeners/azurevoicerequest.py,sha256=iGHIR_o5Ve4FjCw8K7ydiOlAslPl3m72FXYQFKHWJ3c,1892
-aiavatar/listeners/azurewakeword.py,sha256=s_FT_FZs1p-aa4CViTyqOwPzmS5-uwbqkPHmkVCYR2Q,2085
+aiavatar/listeners/azurevoicerequest.py,sha256=7m7xRmkWfTgL8JjFbFOPqZvzydTllAnFipTcM1Ru7nE,2522
+aiavatar/listeners/azurewakeword.py,sha256=Z6cjUUoeXDwVaodg4I5NUNQMY1qVRpJ7Y8_ibQKx_7E,2849
 aiavatar/listeners/voicerequest.py,sha256=cvq9IN_VA0idRzC4UFwkQZ-92IYjll94-ZaijVlLTco,977
 aiavatar/listeners/wakeword.py,sha256=EyG99lS9TKblRs4gni5UwbrfBvrVRfJSOa8QtVHHcO0,1078
 aiavatar/processors/__init__.py,sha256=k6qF1_UopWpaxQ89OxP7-dSVLgnrDCuuZH0Gom0JLLU,178
-aiavatar/processors/chatgpt.py,sha256=7cpf0FOrcUYA5rfPfxRWGMupNDl2FEZmB0UmCzkKw8c,5484
+aiavatar/processors/chatgpt.py,sha256=CyMpH_Nq-HtM50eFMFmOF7cJezk5x6VOHq9OxeTYFBU,6162
 aiavatar/speech/__init__.py,sha256=yiveD86ikoWYYVnpdi1r_6ou5bXr-SOkmnri6ry_qHI,275
 aiavatar/speech/voicevox.py,sha256=kYKwOMysyrZiTvQQlV30MmzqvuYMQvZZiVHLxDUm_bc,2483
-aiavatar-0.4.3.dist-info/LICENSE,sha256=UOZ1F5fFDe3XXvG4oNnkL1-Ecun7zpHzRxjp-XsMeAo,11324
-aiavatar-0.4.3.dist-info/METADATA,sha256=YxlN1Q_2lgH23glNmsJTe_HggjlVMSNmn1pKmDni5NA,12628
-aiavatar-0.4.3.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
-aiavatar-0.4.3.dist-info/top_level.txt,sha256=B14WVaakM_kKuOkCeI-WRP83BJ6APkOyQrn6EXxs8kg,9
-aiavatar-0.4.3.dist-info/RECORD,,
+aiavatar-0.4.4.dist-info/LICENSE,sha256=UOZ1F5fFDe3XXvG4oNnkL1-Ecun7zpHzRxjp-XsMeAo,11324
+aiavatar-0.4.4.dist-info/METADATA,sha256=nFwqShdinmio0LE7lzRAhzhfF97zCCCgmPaw681lqM4,12628
+aiavatar-0.4.4.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
+aiavatar-0.4.4.dist-info/top_level.txt,sha256=B14WVaakM_kKuOkCeI-WRP83BJ6APkOyQrn6EXxs8kg,9
+aiavatar-0.4.4.dist-info/RECORD,,
```

