# Comparing `tmp/gaea_operator-1.2.0.7-py3-none-any.whl.zip` & `tmp/gaea_operator-1.2.0.8-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,105 +1,106 @@
-Zip file size: 143547 bytes, number of entries: 103
--rw-r--r--  2.0 unx      131 b- defN 24-Apr-08 06:21 gaea_operator/__init__.py
--rw-r--r--  2.0 unx      131 b- defN 24-Apr-08 06:21 gaea_operator/components/__init__.py
--rw-r--r--  2.0 unx      131 b- defN 24-Apr-08 06:21 gaea_operator/components/eval/__init__.py
--rw-r--r--  2.0 unx     4169 b- defN 24-Apr-08 06:21 gaea_operator/components/eval/ocrnet.py
--rw-r--r--  2.0 unx     4268 b- defN 24-Apr-08 06:21 gaea_operator/components/eval/ppyoloe_plus.py
--rw-r--r--  2.0 unx     4153 b- defN 24-Apr-08 06:21 gaea_operator/components/eval/resnet.py
--rw-r--r--  2.0 unx     2956 b- defN 24-Apr-08 06:21 gaea_operator/components/inference/__init__.py
--rw-r--r--  2.0 unx     4034 b- defN 24-Apr-08 06:21 gaea_operator/components/inference/inference.py
--rw-r--r--  2.0 unx     3555 b- defN 24-Apr-08 06:21 gaea_operator/components/package/__init__.py
--rw-r--r--  2.0 unx     8375 b- defN 24-Apr-08 06:21 gaea_operator/components/package/package.py
--rw-r--r--  2.0 unx      131 b- defN 24-Apr-08 06:21 gaea_operator/components/train/__init__.py
--rw-r--r--  2.0 unx     7555 b- defN 24-Apr-08 06:21 gaea_operator/components/train/ocrnet.py
--rw-r--r--  2.0 unx     8365 b- defN 24-Apr-08 06:21 gaea_operator/components/train/ppyoloe_plus.py
--rw-r--r--  2.0 unx     7390 b- defN 24-Apr-08 06:21 gaea_operator/components/train/resnet.py
--rw-r--r--  2.0 unx      131 b- defN 24-Apr-08 06:21 gaea_operator/components/transform/__init__.py
--rw-r--r--  2.0 unx     6338 b- defN 24-Apr-08 06:21 gaea_operator/components/transform/ocrnet.py
--rw-r--r--  2.0 unx     6078 b- defN 24-Apr-08 06:21 gaea_operator/components/transform/ppyoloe_plus.py
--rw-r--r--  2.0 unx     6214 b- defN 24-Apr-08 06:21 gaea_operator/components/transform/resnet.py
--rw-r--r--  2.0 unx     3559 b- defN 24-Apr-08 06:21 gaea_operator/components/transform_eval/__init__.py
--rw-r--r--  2.0 unx     7658 b- defN 24-Apr-08 06:21 gaea_operator/components/transform_eval/transform_eval.py
--rw-r--r--  2.0 unx      505 b- defN 24-Apr-08 06:21 gaea_operator/config/__init__.py
--rw-r--r--  2.0 unx     4883 b- defN 24-Apr-08 06:21 gaea_operator/config/config.py
--rw-r--r--  2.0 unx    14048 b- defN 24-Apr-08 06:21 gaea_operator/config/generate_transform_config.py
--rw-r--r--  2.0 unx    14835 b- defN 24-Apr-08 06:21 gaea_operator/config/modify_package_files.py
--rw-r--r--  2.0 unx     3642 b- defN 24-Apr-08 06:21 gaea_operator/config/update_parse.py
--rw-r--r--  2.0 unx    16721 b- defN 24-Apr-08 06:21 gaea_operator/config/update_pbtxt.py
--rw-r--r--  2.0 unx      130 b- defN 24-Apr-08 06:21 gaea_operator/config/ocrnet/__init__.py
--rw-r--r--  2.0 unx     6499 b- defN 24-Apr-08 06:21 gaea_operator/config/ocrnet/ocrnet_config.py
--rw-r--r--  2.0 unx      130 b- defN 24-Apr-08 06:21 gaea_operator/config/ocrnet/template/__init__.py
--rw-r--r--  2.0 unx     8814 b- defN 24-Apr-08 06:21 gaea_operator/config/ocrnet/template/modify_train_parameter.py
--rwxr-xr-x  2.0 unx     1467 b- defN 24-Apr-08 06:21 gaea_operator/config/ocrnet/template/parameter.yaml
--rw-r--r--  2.0 unx      130 b- defN 24-Apr-08 06:21 gaea_operator/config/ppyoloe_plus/__init__.py
--rw-r--r--  2.0 unx     4058 b- defN 24-Apr-08 06:21 gaea_operator/config/ppyoloe_plus/ppyoloeplus_config.py
--rw-r--r--  2.0 unx      130 b- defN 24-Apr-08 06:21 gaea_operator/config/ppyoloe_plus/template/__init__.py
--rw-r--r--  2.0 unx    12621 b- defN 24-Apr-08 06:21 gaea_operator/config/ppyoloe_plus/template/modify_train_parameter.py
--rw-r--r--  2.0 unx     4582 b- defN 24-Apr-08 06:21 gaea_operator/config/ppyoloe_plus/template/parameter.yaml
--rw-r--r--  2.0 unx     4666 b- defN 24-Apr-08 06:21 gaea_operator/config/ppyoloe_plus/template/parameter_c.yaml
--rw-r--r--  2.0 unx      130 b- defN 24-Apr-08 06:21 gaea_operator/config/resnet/__init__.py
--rw-r--r--  2.0 unx     4283 b- defN 24-Apr-08 06:21 gaea_operator/config/resnet/resnet_config.py
--rw-r--r--  2.0 unx    11390 b- defN 24-Apr-08 06:21 gaea_operator/config/resnet/template/modify_train_parameter.py
--rw-r--r--  2.0 unx     2315 b- defN 24-Apr-08 06:21 gaea_operator/config/resnet/template/parameter.yaml
--rw-r--r--  2.0 unx      330 b- defN 24-Apr-08 06:21 gaea_operator/dataset/__init__.py
--rw-r--r--  2.0 unx     3949 b- defN 24-Apr-08 06:21 gaea_operator/dataset/cityscape_dataset.py
--rw-r--r--  2.0 unx     5061 b- defN 24-Apr-08 06:21 gaea_operator/dataset/coco_dataset.py
--rw-r--r--  2.0 unx     4969 b- defN 24-Apr-08 06:21 gaea_operator/dataset/dataset.py
--rw-r--r--  2.0 unx     4306 b- defN 24-Apr-08 06:21 gaea_operator/dataset/imagenet_dataset.py
--rw-r--r--  2.0 unx      584 b- defN 24-Apr-08 06:21 gaea_operator/metric/__init__.py
--rw-r--r--  2.0 unx     5613 b- defN 24-Apr-08 06:21 gaea_operator/metric/metric.py
--rw-r--r--  2.0 unx      433 b- defN 24-Apr-08 06:21 gaea_operator/metric/analysis/__init__.py
--rw-r--r--  2.0 unx    14048 b- defN 24-Apr-08 06:21 gaea_operator/metric/analysis/eval_metric_analysis.py
--rw-r--r--  2.0 unx     5987 b- defN 24-Apr-08 06:21 gaea_operator/metric/analysis/inference_metric_analysis.py
--rw-r--r--  2.0 unx     8902 b- defN 24-Apr-08 06:21 gaea_operator/metric/analysis/label_statistics_metric_analysis.py
--rw-r--r--  2.0 unx      737 b- defN 24-Apr-08 06:21 gaea_operator/metric/operator/__init__.py
--rw-r--r--  2.0 unx     3195 b- defN 24-Apr-08 06:21 gaea_operator/metric/operator/check.py
--rw-r--r--  2.0 unx     1923 b- defN 24-Apr-08 06:21 gaea_operator/metric/operator/metric.py
--rw-r--r--  2.0 unx      701 b- defN 24-Apr-08 06:21 gaea_operator/metric/operator/image/__init__.py
--rw-r--r--  2.0 unx     6960 b- defN 24-Apr-08 06:21 gaea_operator/metric/operator/image/accuracy.py
--rw-r--r--  2.0 unx     2571 b- defN 24-Apr-08 06:21 gaea_operator/metric/operator/image/average_precision.py
--rw-r--r--  2.0 unx     3939 b- defN 24-Apr-08 06:21 gaea_operator/metric/operator/image/confusion_matrix.py
--rw-r--r--  2.0 unx    21177 b- defN 24-Apr-08 06:21 gaea_operator/metric/operator/image/mean_ap.py
--rw-r--r--  2.0 unx     6128 b- defN 24-Apr-08 06:21 gaea_operator/metric/operator/image/mean_iou.py
--rw-r--r--  2.0 unx    19509 b- defN 24-Apr-08 06:21 gaea_operator/metric/operator/image/precision_recall_curve.py
--rw-r--r--  2.0 unx    11271 b- defN 24-Apr-08 06:21 gaea_operator/metric/operator/image/precision_recall_f1score.py
--rw-r--r--  2.0 unx      289 b- defN 24-Apr-08 06:21 gaea_operator/metric/operator/tabular/__init__.py
--rw-r--r--  2.0 unx     1207 b- defN 24-Apr-08 06:21 gaea_operator/metric/operator/tabular/count_statistic.py
--rw-r--r--  2.0 unx     2185 b- defN 24-Apr-08 06:21 gaea_operator/metric/operator/tabular/histogram_statistic.py
--rw-r--r--  2.0 unx     4864 b- defN 24-Apr-08 06:21 gaea_operator/metric/schema/object_detection.yaml
--rw-r--r--  2.0 unx      131 b- defN 24-Apr-08 06:21 gaea_operator/metric/types/__init__.py
--rw-r--r--  2.0 unx     1173 b- defN 24-Apr-08 06:21 gaea_operator/metric/types/image_classification_metric.py
--rw-r--r--  2.0 unx     4874 b- defN 24-Apr-08 06:21 gaea_operator/metric/types/metric.py
--rw-r--r--  2.0 unx     2362 b- defN 24-Apr-08 06:21 gaea_operator/metric/types/object_detection_metric.py
--rw-r--r--  2.0 unx     1244 b- defN 24-Apr-08 06:21 gaea_operator/metric/types/semantic_segmentation_metric.py
--rw-r--r--  2.0 unx      214 b- defN 24-Apr-08 06:21 gaea_operator/model/__init__.py
--rw-r--r--  2.0 unx     1436 b- defN 24-Apr-08 06:21 gaea_operator/model/model.py
--rw-r--r--  2.0 unx      181 b- defN 24-Apr-08 06:21 gaea_operator/trainer/__init__.py
--rw-r--r--  2.0 unx     4979 b- defN 24-Apr-08 06:21 gaea_operator/trainer/trainer.py
--rw-r--r--  2.0 unx      187 b- defN 24-Apr-08 06:21 gaea_operator/transform/__init__.py
--rw-r--r--  2.0 unx     3307 b- defN 24-Apr-08 06:21 gaea_operator/transform/cvt_copy_model.py
--rw-r--r--  2.0 unx      776 b- defN 24-Apr-08 06:21 gaea_operator/transform/transform.py
--rw-r--r--  2.0 unx     1788 b- defN 24-Apr-08 06:21 gaea_operator/utils/__init__.py
--rw-r--r--  2.0 unx     5053 b- defN 24-Apr-08 06:21 gaea_operator/utils/accelerator.py
--rw-r--r--  2.0 unx     2717 b- defN 24-Apr-08 06:21 gaea_operator/utils/compress.py
--rw-r--r--  2.0 unx      426 b- defN 24-Apr-08 06:21 gaea_operator/utils/consts.py
--rw-r--r--  2.0 unx     1948 b- defN 24-Apr-08 06:21 gaea_operator/utils/file.py
--rw-r--r--  2.0 unx     1533 b- defN 24-Apr-08 06:21 gaea_operator/utils/import_module.py
--rw-r--r--  2.0 unx     6613 b- defN 24-Apr-08 06:21 gaea_operator/utils/model_template.py
--rw-r--r--  2.0 unx     1680 b- defN 24-Apr-08 06:21 gaea_operator/utils/registry.py
--rw-r--r--  2.0 unx     1000 b- defN 24-Apr-08 06:21 gaea_operator/utils/tensor.py
--rw-r--r--  2.0 unx      301 b- defN 24-Apr-08 06:21 gaea_operator/utils/time.py
--rw-r--r--  2.0 unx    11390 b- defN 24-Apr-08 06:21 gaea_operator-1.2.0.7.data/data/classify.config/modify_train_parameter.py
--rw-r--r--  2.0 unx     2315 b- defN 24-Apr-08 06:21 gaea_operator-1.2.0.7.data/data/classify.config/parameter.yaml
--rwxr-xr-x  2.0 unx      130 b- defN 24-Apr-08 06:21 gaea_operator-1.2.0.7.data/data/ocrnet.config/__init__.py
--rwxr-xr-x  2.0 unx     8814 b- defN 24-Apr-08 06:21 gaea_operator-1.2.0.7.data/data/ocrnet.config/modify_train_parameter.py
--rwxr-xr-x  2.0 unx     1467 b- defN 24-Apr-08 06:21 gaea_operator-1.2.0.7.data/data/ocrnet.config/parameter.yaml
--rw-r--r--  2.0 unx      130 b- defN 24-Apr-08 06:21 gaea_operator-1.2.0.7.data/data/ppyoloe_plus.config/__init__.py
--rw-r--r--  2.0 unx    12621 b- defN 24-Apr-08 06:21 gaea_operator-1.2.0.7.data/data/ppyoloe_plus.config/modify_train_parameter.py
--rw-r--r--  2.0 unx     4582 b- defN 24-Apr-08 06:21 gaea_operator-1.2.0.7.data/data/ppyoloe_plus.config/parameter.yaml
--rw-r--r--  2.0 unx     4666 b- defN 24-Apr-08 06:21 gaea_operator-1.2.0.7.data/data/ppyoloe_plus.config/parameter_c.yaml
--rw-r--r--  2.0 unx     4864 b- defN 24-Apr-08 06:21 gaea_operator-1.2.0.7.data/data/schema/object_detection.yaml
--rw-r--r--  2.0 unx     2091 b- defN 24-Apr-08 06:21 gaea_operator-1.2.0.7.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 24-Apr-08 06:21 gaea_operator-1.2.0.7.dist-info/WHEEL
--rw-r--r--  2.0 unx       14 b- defN 24-Apr-08 06:21 gaea_operator-1.2.0.7.dist-info/top_level.txt
--rw-rw-r--  2.0 unx    10493 b- defN 24-Apr-08 06:21 gaea_operator-1.2.0.7.dist-info/RECORD
-103 files, 449731 bytes uncompressed, 126307 bytes compressed:  71.9%
+Zip file size: 146106 bytes, number of entries: 104
+-rw-r--r--  2.0 unx      131 b- defN 24-Apr-09 14:23 gaea_operator/__init__.py
+-rw-r--r--  2.0 unx      131 b- defN 24-Apr-09 14:23 gaea_operator/components/__init__.py
+-rw-r--r--  2.0 unx      131 b- defN 24-Apr-09 14:23 gaea_operator/components/eval/__init__.py
+-rw-r--r--  2.0 unx     4169 b- defN 24-Apr-09 14:23 gaea_operator/components/eval/ocrnet.py
+-rw-r--r--  2.0 unx     4268 b- defN 24-Apr-09 14:23 gaea_operator/components/eval/ppyoloe_plus.py
+-rw-r--r--  2.0 unx     4153 b- defN 24-Apr-09 14:23 gaea_operator/components/eval/resnet.py
+-rw-r--r--  2.0 unx     2956 b- defN 24-Apr-09 14:23 gaea_operator/components/inference/__init__.py
+-rw-r--r--  2.0 unx     4034 b- defN 24-Apr-09 14:23 gaea_operator/components/inference/inference.py
+-rw-r--r--  2.0 unx     3555 b- defN 24-Apr-09 14:23 gaea_operator/components/package/__init__.py
+-rw-r--r--  2.0 unx     8375 b- defN 24-Apr-09 14:23 gaea_operator/components/package/package.py
+-rw-r--r--  2.0 unx      131 b- defN 24-Apr-09 14:23 gaea_operator/components/train/__init__.py
+-rw-r--r--  2.0 unx     7555 b- defN 24-Apr-09 14:23 gaea_operator/components/train/ocrnet.py
+-rw-r--r--  2.0 unx     8365 b- defN 24-Apr-09 14:23 gaea_operator/components/train/ppyoloe_plus.py
+-rw-r--r--  2.0 unx     7390 b- defN 24-Apr-09 14:23 gaea_operator/components/train/resnet.py
+-rw-r--r--  2.0 unx      131 b- defN 24-Apr-09 14:23 gaea_operator/components/transform/__init__.py
+-rw-r--r--  2.0 unx     6338 b- defN 24-Apr-09 14:23 gaea_operator/components/transform/ocrnet.py
+-rw-r--r--  2.0 unx     6078 b- defN 24-Apr-09 14:23 gaea_operator/components/transform/ppyoloe_plus.py
+-rw-r--r--  2.0 unx     6214 b- defN 24-Apr-09 14:23 gaea_operator/components/transform/resnet.py
+-rw-r--r--  2.0 unx     3558 b- defN 24-Apr-09 14:23 gaea_operator/components/transform_eval/__init__.py
+-rw-r--r--  2.0 unx     7658 b- defN 24-Apr-09 14:23 gaea_operator/components/transform_eval/transform_eval.py
+-rw-r--r--  2.0 unx      505 b- defN 24-Apr-09 14:23 gaea_operator/config/__init__.py
+-rw-r--r--  2.0 unx     4883 b- defN 24-Apr-09 14:23 gaea_operator/config/config.py
+-rw-r--r--  2.0 unx    14048 b- defN 24-Apr-09 14:23 gaea_operator/config/generate_transform_config.py
+-rw-r--r--  2.0 unx    14835 b- defN 24-Apr-09 14:23 gaea_operator/config/modify_package_files.py
+-rw-r--r--  2.0 unx     3642 b- defN 24-Apr-09 14:23 gaea_operator/config/update_parse.py
+-rw-r--r--  2.0 unx    16721 b- defN 24-Apr-09 14:23 gaea_operator/config/update_pbtxt.py
+-rw-r--r--  2.0 unx      130 b- defN 24-Apr-09 14:23 gaea_operator/config/ocrnet/__init__.py
+-rw-r--r--  2.0 unx     6499 b- defN 24-Apr-09 14:23 gaea_operator/config/ocrnet/ocrnet_config.py
+-rw-r--r--  2.0 unx      130 b- defN 24-Apr-09 14:23 gaea_operator/config/ocrnet/template/__init__.py
+-rw-r--r--  2.0 unx     8814 b- defN 24-Apr-09 14:23 gaea_operator/config/ocrnet/template/modify_train_parameter.py
+-rwxr-xr-x  2.0 unx     1467 b- defN 24-Apr-09 14:23 gaea_operator/config/ocrnet/template/parameter.yaml
+-rw-r--r--  2.0 unx      130 b- defN 24-Apr-09 14:23 gaea_operator/config/ppyoloe_plus/__init__.py
+-rw-r--r--  2.0 unx     4058 b- defN 24-Apr-09 14:23 gaea_operator/config/ppyoloe_plus/ppyoloeplus_config.py
+-rw-r--r--  2.0 unx      130 b- defN 24-Apr-09 14:23 gaea_operator/config/ppyoloe_plus/template/__init__.py
+-rw-r--r--  2.0 unx    12621 b- defN 24-Apr-09 14:23 gaea_operator/config/ppyoloe_plus/template/modify_train_parameter.py
+-rw-r--r--  2.0 unx     4582 b- defN 24-Apr-09 14:23 gaea_operator/config/ppyoloe_plus/template/parameter.yaml
+-rw-r--r--  2.0 unx     4666 b- defN 24-Apr-09 14:23 gaea_operator/config/ppyoloe_plus/template/parameter_c.yaml
+-rw-r--r--  2.0 unx      130 b- defN 24-Apr-09 14:23 gaea_operator/config/resnet/__init__.py
+-rw-r--r--  2.0 unx     4283 b- defN 24-Apr-09 14:23 gaea_operator/config/resnet/resnet_config.py
+-rw-r--r--  2.0 unx    11390 b- defN 24-Apr-09 14:23 gaea_operator/config/resnet/template/modify_train_parameter.py
+-rw-r--r--  2.0 unx     2315 b- defN 24-Apr-09 14:23 gaea_operator/config/resnet/template/parameter.yaml
+-rw-r--r--  2.0 unx      330 b- defN 24-Apr-09 14:23 gaea_operator/dataset/__init__.py
+-rw-r--r--  2.0 unx     3949 b- defN 24-Apr-09 14:23 gaea_operator/dataset/cityscape_dataset.py
+-rw-r--r--  2.0 unx     5061 b- defN 24-Apr-09 14:23 gaea_operator/dataset/coco_dataset.py
+-rw-r--r--  2.0 unx     4969 b- defN 24-Apr-09 14:23 gaea_operator/dataset/dataset.py
+-rw-r--r--  2.0 unx     4306 b- defN 24-Apr-09 14:23 gaea_operator/dataset/imagenet_dataset.py
+-rw-r--r--  2.0 unx      584 b- defN 24-Apr-09 14:23 gaea_operator/metric/__init__.py
+-rw-r--r--  2.0 unx     5613 b- defN 24-Apr-09 14:23 gaea_operator/metric/metric.py
+-rw-r--r--  2.0 unx      433 b- defN 24-Apr-09 14:23 gaea_operator/metric/analysis/__init__.py
+-rw-r--r--  2.0 unx    15383 b- defN 24-Apr-09 14:23 gaea_operator/metric/analysis/eval_metric_analysis.py
+-rw-r--r--  2.0 unx     6532 b- defN 24-Apr-09 14:23 gaea_operator/metric/analysis/inference_metric_analysis.py
+-rw-r--r--  2.0 unx    11301 b- defN 24-Apr-09 14:23 gaea_operator/metric/analysis/label_statistics_metric_analysis.py
+-rw-r--r--  2.0 unx      792 b- defN 24-Apr-09 14:23 gaea_operator/metric/operator/__init__.py
+-rw-r--r--  2.0 unx     3195 b- defN 24-Apr-09 14:23 gaea_operator/metric/operator/check.py
+-rw-r--r--  2.0 unx     1923 b- defN 24-Apr-09 14:23 gaea_operator/metric/operator/metric.py
+-rw-r--r--  2.0 unx      779 b- defN 24-Apr-09 14:23 gaea_operator/metric/operator/image/__init__.py
+-rw-r--r--  2.0 unx     6960 b- defN 24-Apr-09 14:23 gaea_operator/metric/operator/image/accuracy.py
+-rw-r--r--  2.0 unx     2571 b- defN 24-Apr-09 14:23 gaea_operator/metric/operator/image/average_precision.py
+-rw-r--r--  2.0 unx     5264 b- defN 24-Apr-09 14:23 gaea_operator/metric/operator/image/bbox_confusion_matrix.py
+-rw-r--r--  2.0 unx     3939 b- defN 24-Apr-09 14:23 gaea_operator/metric/operator/image/confusion_matrix.py
+-rw-r--r--  2.0 unx    20678 b- defN 24-Apr-09 14:23 gaea_operator/metric/operator/image/mean_ap.py
+-rw-r--r--  2.0 unx     6128 b- defN 24-Apr-09 14:23 gaea_operator/metric/operator/image/mean_iou.py
+-rw-r--r--  2.0 unx    19509 b- defN 24-Apr-09 14:23 gaea_operator/metric/operator/image/precision_recall_curve.py
+-rw-r--r--  2.0 unx    11271 b- defN 24-Apr-09 14:23 gaea_operator/metric/operator/image/precision_recall_f1score.py
+-rw-r--r--  2.0 unx      289 b- defN 24-Apr-09 14:23 gaea_operator/metric/operator/tabular/__init__.py
+-rw-r--r--  2.0 unx     1207 b- defN 24-Apr-09 14:23 gaea_operator/metric/operator/tabular/count_statistic.py
+-rw-r--r--  2.0 unx     2185 b- defN 24-Apr-09 14:23 gaea_operator/metric/operator/tabular/histogram_statistic.py
+-rw-r--r--  2.0 unx     4864 b- defN 24-Apr-09 14:23 gaea_operator/metric/schema/object_detection.yaml
+-rw-r--r--  2.0 unx      131 b- defN 24-Apr-09 14:23 gaea_operator/metric/types/__init__.py
+-rw-r--r--  2.0 unx     1173 b- defN 24-Apr-09 14:23 gaea_operator/metric/types/image_classification_metric.py
+-rw-r--r--  2.0 unx     4874 b- defN 24-Apr-09 14:23 gaea_operator/metric/types/metric.py
+-rw-r--r--  2.0 unx     2362 b- defN 24-Apr-09 14:23 gaea_operator/metric/types/object_detection_metric.py
+-rw-r--r--  2.0 unx     1244 b- defN 24-Apr-09 14:23 gaea_operator/metric/types/semantic_segmentation_metric.py
+-rw-r--r--  2.0 unx      214 b- defN 24-Apr-09 14:23 gaea_operator/model/__init__.py
+-rw-r--r--  2.0 unx     1436 b- defN 24-Apr-09 14:23 gaea_operator/model/model.py
+-rw-r--r--  2.0 unx      181 b- defN 24-Apr-09 14:23 gaea_operator/trainer/__init__.py
+-rw-r--r--  2.0 unx     4979 b- defN 24-Apr-09 14:23 gaea_operator/trainer/trainer.py
+-rw-r--r--  2.0 unx      187 b- defN 24-Apr-09 14:23 gaea_operator/transform/__init__.py
+-rw-r--r--  2.0 unx     3307 b- defN 24-Apr-09 14:23 gaea_operator/transform/cvt_copy_model.py
+-rw-r--r--  2.0 unx      776 b- defN 24-Apr-09 14:23 gaea_operator/transform/transform.py
+-rw-r--r--  2.0 unx     1788 b- defN 24-Apr-09 14:23 gaea_operator/utils/__init__.py
+-rw-r--r--  2.0 unx     5554 b- defN 24-Apr-09 14:23 gaea_operator/utils/accelerator.py
+-rw-r--r--  2.0 unx     2717 b- defN 24-Apr-09 14:23 gaea_operator/utils/compress.py
+-rw-r--r--  2.0 unx      426 b- defN 24-Apr-09 14:23 gaea_operator/utils/consts.py
+-rw-r--r--  2.0 unx     1948 b- defN 24-Apr-09 14:23 gaea_operator/utils/file.py
+-rw-r--r--  2.0 unx     1533 b- defN 24-Apr-09 14:23 gaea_operator/utils/import_module.py
+-rw-r--r--  2.0 unx     6613 b- defN 24-Apr-09 14:23 gaea_operator/utils/model_template.py
+-rw-r--r--  2.0 unx     1680 b- defN 24-Apr-09 14:23 gaea_operator/utils/registry.py
+-rw-r--r--  2.0 unx     1000 b- defN 24-Apr-09 14:23 gaea_operator/utils/tensor.py
+-rw-r--r--  2.0 unx      301 b- defN 24-Apr-09 14:23 gaea_operator/utils/time.py
+-rw-r--r--  2.0 unx    11390 b- defN 24-Apr-09 14:23 gaea_operator-1.2.0.8.data/data/classify.config/modify_train_parameter.py
+-rw-r--r--  2.0 unx     2315 b- defN 24-Apr-09 14:23 gaea_operator-1.2.0.8.data/data/classify.config/parameter.yaml
+-rwxr-xr-x  2.0 unx      130 b- defN 24-Apr-09 14:23 gaea_operator-1.2.0.8.data/data/ocrnet.config/__init__.py
+-rwxr-xr-x  2.0 unx     8814 b- defN 24-Apr-09 14:23 gaea_operator-1.2.0.8.data/data/ocrnet.config/modify_train_parameter.py
+-rwxr-xr-x  2.0 unx     1467 b- defN 24-Apr-09 14:23 gaea_operator-1.2.0.8.data/data/ocrnet.config/parameter.yaml
+-rw-r--r--  2.0 unx      130 b- defN 24-Apr-09 14:23 gaea_operator-1.2.0.8.data/data/ppyoloe_plus.config/__init__.py
+-rw-r--r--  2.0 unx    12621 b- defN 24-Apr-09 14:23 gaea_operator-1.2.0.8.data/data/ppyoloe_plus.config/modify_train_parameter.py
+-rw-r--r--  2.0 unx     4582 b- defN 24-Apr-09 14:23 gaea_operator-1.2.0.8.data/data/ppyoloe_plus.config/parameter.yaml
+-rw-r--r--  2.0 unx     4666 b- defN 24-Apr-09 14:23 gaea_operator-1.2.0.8.data/data/ppyoloe_plus.config/parameter_c.yaml
+-rw-r--r--  2.0 unx     4864 b- defN 24-Apr-09 14:23 gaea_operator-1.2.0.8.data/data/schema/object_detection.yaml
+-rw-r--r--  2.0 unx     2091 b- defN 24-Apr-09 14:23 gaea_operator-1.2.0.8.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 24-Apr-09 14:23 gaea_operator-1.2.0.8.dist-info/WHEEL
+-rw-r--r--  2.0 unx       14 b- defN 24-Apr-09 14:23 gaea_operator-1.2.0.8.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx    10611 b- defN 24-Apr-09 14:23 gaea_operator-1.2.0.8.dist-info/RECORD
+104 files, 459526 bytes uncompressed, 128670 bytes compressed:  72.0%
```

## zipnote {}

```diff
@@ -168,14 +168,17 @@
 
 Filename: gaea_operator/metric/operator/image/accuracy.py
 Comment: 
 
 Filename: gaea_operator/metric/operator/image/average_precision.py
 Comment: 
 
+Filename: gaea_operator/metric/operator/image/bbox_confusion_matrix.py
+Comment: 
+
 Filename: gaea_operator/metric/operator/image/confusion_matrix.py
 Comment: 
 
 Filename: gaea_operator/metric/operator/image/mean_ap.py
 Comment: 
 
 Filename: gaea_operator/metric/operator/image/mean_iou.py
@@ -261,50 +264,50 @@
 
 Filename: gaea_operator/utils/tensor.py
 Comment: 
 
 Filename: gaea_operator/utils/time.py
 Comment: 
 
-Filename: gaea_operator-1.2.0.7.data/data/classify.config/modify_train_parameter.py
+Filename: gaea_operator-1.2.0.8.data/data/classify.config/modify_train_parameter.py
 Comment: 
 
-Filename: gaea_operator-1.2.0.7.data/data/classify.config/parameter.yaml
+Filename: gaea_operator-1.2.0.8.data/data/classify.config/parameter.yaml
 Comment: 
 
-Filename: gaea_operator-1.2.0.7.data/data/ocrnet.config/__init__.py
+Filename: gaea_operator-1.2.0.8.data/data/ocrnet.config/__init__.py
 Comment: 
 
-Filename: gaea_operator-1.2.0.7.data/data/ocrnet.config/modify_train_parameter.py
+Filename: gaea_operator-1.2.0.8.data/data/ocrnet.config/modify_train_parameter.py
 Comment: 
 
-Filename: gaea_operator-1.2.0.7.data/data/ocrnet.config/parameter.yaml
+Filename: gaea_operator-1.2.0.8.data/data/ocrnet.config/parameter.yaml
 Comment: 
 
-Filename: gaea_operator-1.2.0.7.data/data/ppyoloe_plus.config/__init__.py
+Filename: gaea_operator-1.2.0.8.data/data/ppyoloe_plus.config/__init__.py
 Comment: 
 
-Filename: gaea_operator-1.2.0.7.data/data/ppyoloe_plus.config/modify_train_parameter.py
+Filename: gaea_operator-1.2.0.8.data/data/ppyoloe_plus.config/modify_train_parameter.py
 Comment: 
 
-Filename: gaea_operator-1.2.0.7.data/data/ppyoloe_plus.config/parameter.yaml
+Filename: gaea_operator-1.2.0.8.data/data/ppyoloe_plus.config/parameter.yaml
 Comment: 
 
-Filename: gaea_operator-1.2.0.7.data/data/ppyoloe_plus.config/parameter_c.yaml
+Filename: gaea_operator-1.2.0.8.data/data/ppyoloe_plus.config/parameter_c.yaml
 Comment: 
 
-Filename: gaea_operator-1.2.0.7.data/data/schema/object_detection.yaml
+Filename: gaea_operator-1.2.0.8.data/data/schema/object_detection.yaml
 Comment: 
 
-Filename: gaea_operator-1.2.0.7.dist-info/METADATA
+Filename: gaea_operator-1.2.0.8.dist-info/METADATA
 Comment: 
 
-Filename: gaea_operator-1.2.0.7.dist-info/WHEEL
+Filename: gaea_operator-1.2.0.8.dist-info/WHEEL
 Comment: 
 
-Filename: gaea_operator-1.2.0.7.dist-info/top_level.txt
+Filename: gaea_operator-1.2.0.8.dist-info/top_level.txt
 Comment: 
 
-Filename: gaea_operator-1.2.0.7.dist-info/RECORD
+Filename: gaea_operator-1.2.0.8.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## gaea_operator/components/transform_eval/__init__.py

```diff
@@ -33,15 +33,15 @@
                              "windmill_endpoint": windmill_endpoint,
                              "experiment_name": experiment_name,
                              "experiment_kind": experiment_kind,
                              "tracking_uri": tracking_uri,
                              "project_name": project_name,
                              "model_store_name": modelstore_name,
                              "accelerator": accelerator,
-                             "advanced_parameters": '{"conf_threshold":"0.1",'
+                             "advanced_parameters": '{"conf_threshold":"0.5",'
                                                     '"iou_threshold":"0.50"}'}
     transform_eval_env = {"PF_JOB_FLAVOUR": "{{flavour}}",
                           "PF_JOB_QUEUE_NAME": "{{queue}}",
                           "WINDMILL_AK": "{{windmill_ak}}",
                           "WINDMILL_SK": "{{windmill_sk}}",
                           "WINDMILL_ENDPOINT": "{{windmill_endpoint}}",
                           "EXPERIMENT_KIND": "{{experiment_kind}}",
@@ -62,9 +62,8 @@
                                    outputs={"output_uri": Artifact()},
                                    command=f'python3 -m gaea_operator.components.transform_eval.transform_eval '
                                            f'--algorithm={algorithm} '
                                            f'--input-model-uri={{{{input_model_uri}}}} '
                                            f'--input-dataset-uri={{{{input_dataset_uri}}}} '
                                            f'--output-uri={{{{output_uri}}}}')
 
-
     return transform_eval
```

## gaea_operator/metric/analysis/eval_metric_analysis.py

```diff
@@ -10,14 +10,15 @@
 from typing import List, Dict
 import copy
 from collections import defaultdict
 import logging
 
 from gaea_operator.utils import write_file
 from gaea_operator.metric.operator import MeanAveragePrecision, \
+    BboxConfusionMatrix, \
     Accuracy, \
     PrecisionRecallF1score, \
     ConfusionMatrix, \
     MeanIoU
 from gaea_operator.metric.types.metric import BOUNDING_BOX_MEAN_AVERAGE_RECALL_METRIC_NAME, \
     CONFUSION_MATRIX_METRIC_NAME, \
     BOUNDING_BOX_LABEL_AVERAGE_PRECISION_METRIC_NAME, \
@@ -44,19 +45,26 @@
 
 
 class EvalMetricAnalysis(object):
     """
     Evaluation metric analysis.
     """
 
-    def __init__(self, category: str, labels: List = None, images: List[Dict] = None):
+    def __init__(self,
+                 category: str,
+                 labels: List = None,
+                 images: List[Dict] = None,
+                 conf_threshold: float = 0,
+                 iou_threshold: float = 0.5):
         self.labels = labels
         self.images = images
         self.category = category
         self.data_format_valid = True
+        self.conf_threshold = conf_threshold
+        self.iou_threshold = iou_threshold
 
         self.image_dict = {}
         self.img_id_str2int = {}
         self.labels = []
         self.label_id2index = {}
         self.label_index2id = {}
         self.label_id2name = {}
@@ -101,15 +109,19 @@
     def set_metric(self):
         """
         Set metric.
         """
         if self.category == "Image/ObjectDetection":
             self.metric = [MeanAveragePrecision(labels=self.labels,
                                                 num_classes=len(self.labels),
-                                                classwise=True)]
+                                                classwise=True),
+                           BboxConfusionMatrix(labels=self.labels,
+                                               conf_threshold=self.conf_threshold,
+                                               iou_threshold=self.iou_threshold,
+                                               num_classes=len(self.labels))]
             self.format_input = self._format_to_object_detection
             self.format_result = self._format_object_detection_result
         elif self.category == "Image/ImageClassification/MultiClass":
             self.metric = [Accuracy(num_classes=len(self.labels)),
                            PrecisionRecallF1score(num_classes=len(self.labels), average="none"),
                            ConfusionMatrix(num_classes=len(self.labels))]
             self.format_input = self._format_to_classification
@@ -134,36 +146,23 @@
         for metric in self.metric:
             metric.update(predictions=predictions, references=references)
 
     def _format_to_object_detection(self, predictions: List[Dict], references: List[Dict]):
         """
         Format to object detection metric.
         """
-        predictions_list = []
-        ann_id = 1
-        for item in predictions:
-            im_id = item["image_id"]
-            im_id_int = self.img_id_str2int[im_id]
-            for anno in item["annotations"]:
-                anno["image_id"] = im_id_int
-                for idx in range(len(anno["labels"])):
-                    anno_copy = copy.deepcopy(anno)
-                    anno_copy["id"] = ann_id
-                    anno_copy['category_id'] = int(anno["labels"][idx]["id"])
-                    anno_copy['score'] = anno["labels"][idx]["confidence"]
-                    predictions_list.append(anno_copy)
-                    ann_id += 1
-
         ann_id = 1
         references_dict = defaultdict(list)
         for item in references:
             im_id = item["image_id"]
             img = self.image_dict[im_id]
             im_id_int = self.img_id_str2int[im_id]
             if item["annotations"] is None:
+                anno = {"id": ann_id, "image_id": im_id_int, "width": img["width"], "height": img["height"]}
+                references_dict[im_id_int].append(anno)
                 continue
             for anno in item["annotations"]:
                 anno["id"] = ann_id
                 anno["image_id"] = im_id_int
                 anno["width"] = img["width"]
                 anno["height"] = img["height"]
                 anno['ignore'] = anno['ignore'] if 'ignore' in anno else 0
@@ -172,66 +171,91 @@
                     anno["labels"][0]["id"] = int(anno["labels"][0]["id"])
                 if math.isnan(anno["labels"][0]["id"]):
                     continue
                 anno['category_id'] = int(anno["labels"][0]["id"])
                 references_dict[im_id_int].append(anno)
                 ann_id += 1
 
-        for im_id in self.image_dict:
-            if self.img_id_str2int[im_id] not in references_dict:
-                references_dict[self.img_id_str2int[im_id]] = []
+        predictions_list = []
+        ann_id = 1
+        for item in predictions:
+            im_id = item["image_id"]
+            im_id_int = self.img_id_str2int[im_id]
+            # 如果预测结果不在 gt里面，是一张未标注的图片，不参与指标计算
+            if item["annotations"] is None or im_id_int not in references_dict:
+                continue
+            for anno in item["annotations"]:
+                anno["image_id"] = im_id_int
+                for idx in range(len(anno["labels"])):
+                    anno_copy = copy.deepcopy(anno)
+                    anno_copy["id"] = ann_id
+                    anno_copy['category_id'] = int(anno["labels"][idx]["id"])
+                    anno_copy['score'] = anno["labels"][idx]["confidence"]
+                    predictions_list.append(anno_copy)
+                    ann_id += 1
 
         references_list = []
         for _, anno in references_dict.items():
             references_list.extend(anno)
 
         return {"bbox": predictions_list}, {"bbox": references_list}
 
     def _format_object_detection_result(self, metric_result: Dict):
         metric = ObjectDetectionMetric(labels=self.labels, metrics=[])
-        metric_result = metric_result[MeanAveragePrecision.global_name()]
+        bbox_metric_result = metric_result[MeanAveragePrecision.global_name()]
         bounding_box_mean_average_precision = BoundingBoxMeanAveragePrecision(
             name=BOUNDING_BOX_MEAN_AVERAGE_PRECISION_METRIC_NAME,
             displayName="AP50指标",
-            result=metric_result["bbox"][1])
+            result=bbox_metric_result["bbox"][1])
         bounding_box_mean_average_recall = BoundingBoxMeanAverageRecall(
             name=BOUNDING_BOX_MEAN_AVERAGE_RECALL_METRIC_NAME,
             displayName="AR50指标",
-            result=metric_result["bbox"][8])
+            result=bbox_metric_result["bbox"][8])
         bounding_box_label_average_precision = BoundingBoxLabelAveragePrecision(
             name=BOUNDING_BOX_LABEL_AVERAGE_PRECISION_METRIC_NAME,
             displayName="类别AP结果",
             result=[])
         confusion_matrix = ConfusionMatrixMetric(
             name=CONFUSION_MATRIX_METRIC_NAME,
             displayName="混淆矩阵",
             result=ConfusionMatrixMetricResult(annotationSpecs=[], rows=[]))
         bounding_box_label_metric = BoundingBoxLabelMetric(name=BOUNDING_BOX_LABEL_METRIC_NAME,
                                                            displayName="PR曲线",
                                                            result=[])
-        for item in metric_result["bbox_results_per_label"]:
+        for item in bbox_metric_result["bbox_results_per_label"]:
             bounding_box_label_average_precision.result.append(
                 BoundingBoxLabelAveragePrecisionResult(labelName=item["labelName"],
                                                        averagePrecision=item["averagePrecision"]))
-        for label_id, item in metric_result["confusion_matrix"].items():
-            annotation_spec = ConfusionMatrixAnnotationSpec(id=label_id, labelName=self.label_id2name[label_id])
-            row = ConfusionMatrixRow(row=item)
-            confusion_matrix.result.annotationSpecs.append(annotation_spec)
-            confusion_matrix.result.rows.append(row)
-        for item in metric_result["pr_curve"]:
+        for item in bbox_metric_result["pr_curve"]:
             bounding_box_label_metric_result = BoundingBoxLabelMetricResult(labelName=item[0],
                                                                             iouThreshold=0.5,
                                                                             averagePrecision=item[1],
                                                                             confidenceMetrics=[])
             for idx, p in enumerate(item[2]):
                 bounding_box_label_metric_result.confidenceMetrics.append(
                     BoundingBoxLabelConfidenceMetric(
                         precision=p,
                         recall=item[3][idx]))
             bounding_box_label_metric.result.append(bounding_box_label_metric_result)
+        lower_bound, upper_bound = 0, 0
+        for idx, item in enumerate(metric_result[BboxConfusionMatrix.global_name()]):
+            lower_bound = min(lower_bound, min(item))
+            upper_bound = max(upper_bound, max(item))
+            if idx not in self.label_index2id:
+                label_id = max(self.label_index2id.values()) + 1
+                label_name = "无标签"
+            else:
+                label_id = self.label_index2id[idx]
+                label_name = self.label_index2name[idx]
+            annotation_spec = ConfusionMatrixAnnotationSpec(id=label_id, labelName=label_name)
+            row = ConfusionMatrixRow(row=item)
+            confusion_matrix.result.annotationSpecs.append(annotation_spec)
+            confusion_matrix.result.rows.append(row)
+            confusion_matrix.result.lowerBound = lower_bound
+            confusion_matrix.result.upperBound = upper_bound
 
         metric.metrics.extend([bounding_box_mean_average_precision,
                                bounding_box_mean_average_recall,
                                bounding_box_label_average_precision,
                                bounding_box_label_metric,
                                confusion_matrix])
         return metric.dict()
```

## gaea_operator/metric/analysis/inference_metric_analysis.py

```diff
@@ -19,17 +19,24 @@
 
 
 class InferenceMetricAnalysis(object):
     """
     Inference metric analysis.
     """
 
-    def __init__(self, labels: List = None, images: List[Dict] = None):
+    def __init__(self,
+                 labels: List = None,
+                 images: List[Dict] = None,
+                 conf_threshold: float = 0,
+                 iou_threshold: float = 0.5):
         self.labels = labels
         self.images = images
+        self.conf_threshold = conf_threshold
+        self.iou_threshold = iou_threshold
+
         self.image_dict = {}
         self.img_id_str2int = {}
         self.label_id2index = {}
         self.label_name2id = {}
         self.metric = {}
         self.set_images(images)
         self.set_labels(labels)
@@ -83,24 +90,31 @@
     def _format_input(self, predictions: List[Dict], references: List[Dict]):
         """
         Format to object detection metric.
         """
         predictions_list = []
         for item in predictions:
             array_item = np.zeros(len(self.labels), dtype=np.int8)
+            if item["annotations"] is None:
+                predictions_list.append(array_item)
+                continue
             for anno in item["annotations"]:
                 for idx in range(len(anno["labels"])):
-                    label_id = int(anno["labels"][idx]["id"])
-                    index = self.label_id2index[label_id]
-                    array_item[index] = 1
+                    if anno["labels"][idx]["confidence"] > self.conf_threshold:
+                        label_id = int(anno["labels"][idx]["id"])
+                        index = self.label_id2index[label_id]
+                        array_item[index] = 1
             predictions_list.append(array_item)
 
         references_list = []
         for item in references:
             array_item = np.zeros(len(self.labels), dtype=np.int8)
+            if item["annotations"] is None:
+                references_list.append(array_item)
+                continue
             for anno in item["annotations"]:
                 for idx in range(len(anno["labels"])):
                     if isinstance(anno["labels"][idx]["id"], int) or isinstance(anno["labels"][idx]["id"], str):
                         label_id = int(anno["labels"][idx]["id"])
                         index = self.label_id2index[label_id]
                         array_item[index] = 1
             references_list.append(array_item)
```

## gaea_operator/metric/analysis/label_statistics_metric_analysis.py

```diff
@@ -25,40 +25,86 @@
     ANNOTATION_HEIGHT_STATISTIC_METRIC
 
 
 class LabelStatisticMetricAnalysis(object):
     """
     Label statistic metric analysis.
     """
-    def __init__(self, labels: List):
+
+    def __init__(self, category: str, labels: List = None, images: List[Dict] = None, ):
         self.labels = labels
-        self.labels = [{"id": int(label["id"]), "name": label["name"]} for label in self.labels]
+        self.images = images
+        self.category = category
 
-        self.label_id2index = {label["id"]: idx for idx, label in enumerate(self.labels)}
-        self.label_index2name = {idx: label["name"] for idx, label in enumerate(self.labels)}
-        self.label_name2id = {label["name"]: label["id"] for idx, label in enumerate(self.labels)}
+        self.image_dict = {}
+        self.img_id_str2int = {}
+        self.labels = []
+        self.label_id2index = {}
+        self.label_index2id = {}
+        self.label_id2name = {}
+        self.label_name2id = {}
+        self.label_index2name = {}
+        self.metric = {}
 
-        self.metric = {LABEL_STATISTIC_METRIC: CountStatistic(num_classes=len(self.labels), labels=self.labels),
-                       ANNOTATION_CONFIDENCE_STATISTIC_METRIC: HistogramStatistic(num_classes=len(self.labels),
-                                                                                  labels=self.labels,
-                                                                                  range=(0, 1)),
-                       ANNOTATION_AREA_STATISTIC_METRIC: HistogramStatistic(num_classes=len(self.labels),
-                                                                            labels=self.labels),
-                       ANNOTATION_WIDTH_STATISTIC_METRIC: HistogramStatistic(num_classes=len(self.labels),
-                                                                             labels=self.labels),
-                       ANNOTATION_HEIGHT_STATISTIC_METRIC: HistogramStatistic(num_classes=len(self.labels),
-                                                                              labels=self.labels)}
+        self.set_images(images)
+        self.set_labels(labels)
 
     def reset(self):
         """
         Reset metric.
         """
         for _, metric in self.metric.items():
             metric.reset()
 
+    def set_images(self, images: List[Dict]):
+        """
+        Set images.
+        """
+        if images is None:
+            return
+        self.image_dict = {item["image_id"]: item for item in images}
+        self.img_id_str2int = {key: idx + 1 for idx, key in enumerate(self.image_dict)}
+
+    def set_labels(self, labels: List):
+        """
+        Set labels.
+        """
+        if labels is None:
+            return
+        self.labels = [{"id": int(label["id"]), "name": label["name"]} for label in labels]
+        self.label_id2index = {label["id"]: idx for idx, label in enumerate(self.labels)}
+        self.label_index2id = {idx: label["id"] for idx, label in enumerate(self.labels)}
+        self.label_id2name = {label["id"]: label["name"] for label in self.labels}
+        self.label_name2id = {label["name"]: label["id"] for idx, label in enumerate(self.labels)}
+        self.label_index2name = {idx: label["name"] for idx, label in enumerate(self.labels)}
+        self.set_metric()
+
+    def set_metric(self):
+        """
+        Set metric.
+        """
+        if self.category == "Image/ObjectDetection" or self.category == "Image/SemanticSegmentation":
+            self.metric = {LABEL_STATISTIC_METRIC: CountStatistic(num_classes=len(self.labels), labels=self.labels),
+                           ANNOTATION_CONFIDENCE_STATISTIC_METRIC: HistogramStatistic(num_classes=len(self.labels),
+                                                                                      labels=self.labels,
+                                                                                      range=(0, 1)),
+                           ANNOTATION_AREA_STATISTIC_METRIC: HistogramStatistic(num_classes=len(self.labels),
+                                                                                labels=self.labels),
+                           ANNOTATION_WIDTH_STATISTIC_METRIC: HistogramStatistic(num_classes=len(self.labels),
+                                                                                 labels=self.labels),
+                           ANNOTATION_HEIGHT_STATISTIC_METRIC: HistogramStatistic(num_classes=len(self.labels),
+                                                                                  labels=self.labels)}
+        elif self.category == "Image/ImageClassification/MultiClass":
+            self.metric = {LABEL_STATISTIC_METRIC: CountStatistic(num_classes=len(self.labels), labels=self.labels),
+                           ANNOTATION_CONFIDENCE_STATISTIC_METRIC: HistogramStatistic(num_classes=len(self.labels),
+                                                                                      labels=self.labels,
+                                                                                      range=(0, 1))}
+        else:
+            raise ValueError(f"Unknown category: {self.category}")
+
     def update(self, predictions: List[Dict], references: List[Dict]):
         """
         Update metric.
         """
         annotations = predictions if predictions is not None else references
         assert annotations is not None, "annotations should not be None"
         annotation_dict = self._format_input(annotations)
@@ -84,23 +130,24 @@
                     pred_array = np.zeros(len(self.labels))
                     if isinstance(anno["labels"][0]["id"], str):
                         anno["labels"][0]["id"] = int(anno["labels"][0]["id"])
                     if math.isnan(anno["labels"][0]["id"]):
                         continue
                     column_index = self.label_id2index[int(anno["labels"][idx]["id"])]
                     label_name = self.label_index2name[column_index]
-                    confidence = anno["labels"][idx]["confidence"]
+                    confidence = anno["labels"][idx].get("confidence", 1)
                     pred_array[column_index] = 1
                     annotation_dict[LABEL_STATISTIC_METRIC].append(pred_array)
                     annotation_dict[ANNOTATION_CONFIDENCE_STATISTIC_METRIC][label_name].append(confidence)
-                    if "area" in anno:
-                        annotation_dict[ANNOTATION_AREA_STATISTIC_METRIC][label_name].append(anno["area"])
-                    if "bbox" in anno:
-                        annotation_dict[ANNOTATION_WIDTH_STATISTIC_METRIC][label_name].append(anno["bbox"][2])
-                        annotation_dict[ANNOTATION_HEIGHT_STATISTIC_METRIC][label_name].append(anno["bbox"][3])
+                    if self.category == "Image/ObjectDetection" or self.category == "Image/SemanticSegmentation":
+                        if "area" in anno:
+                            annotation_dict[ANNOTATION_AREA_STATISTIC_METRIC][label_name].append(anno["area"])
+                        if "bbox" in anno:
+                            annotation_dict[ANNOTATION_WIDTH_STATISTIC_METRIC][label_name].append(anno["bbox"][2])
+                            annotation_dict[ANNOTATION_HEIGHT_STATISTIC_METRIC][label_name].append(anno["bbox"][3])
 
         return annotation_dict
 
     def _format_result(self, metric_result: Dict):
         metric = LabelStatisticsMetric(labels=self.labels, metrics=[])
         label_count = LabelCountStatistic(name=LABEL_STATISTIC_METRIC,
                                           displayName="标签统计",
@@ -133,15 +180,22 @@
                 for idx, label_name in self.label_index2name.items():
                     label_cut_statistic_result = LabelCutStatisticResult(labelName=label_name,
                                                                          statisticMetrics=[])
 
                     self._format_cut_statistic(result[label_name], label_cut_statistic_result)
                     key2statistic[key].result.append(label_cut_statistic_result)
 
-        metric.metrics.extend([label_count, label_confidence_cut, label_area_cut, label_width_cut, label_height_cut])
+        if self.category == "Image/ObjectDetection" or self.category == "Image/SemanticSegmentation":
+            metric.metrics.extend([label_count,
+                                   label_confidence_cut,
+                                   label_area_cut,
+                                   label_width_cut,
+                                   label_height_cut])
+        if self.category == "ImageClassification/MultiClass":
+            metric.metrics.extend([label_count, label_confidence_cut])
 
         return metric.dict()
 
     def _format_cut_statistic(self, anno_res, statistic: LabelCutStatisticResult):
         for value in anno_res:
             cut_statistic = StatisticMetric(bboxCount=value[0], lowerBound=value[1], upperBound=value[2])
             statistic.statisticMetrics.append(cut_statistic)
```

## gaea_operator/metric/operator/__init__.py

```diff
@@ -3,22 +3,23 @@
 """
 @File          : __init__.py.py    
 @Author        : yanxiaodong
 @Date          : 2023/5/29
 @Description   :
 """
 from .image import Accuracy, PrecisionRecallF1score, Precision, Recall, F1score, ConfusionMatrix, \
-    PrecisionRecallCurve, AveragePrecision, MeanAveragePrecision, MeanIoU
+    PrecisionRecallCurve, AveragePrecision, MeanAveragePrecision, MeanIoU, BboxConfusionMatrix
 from .tabular import CountStatistic, HistogramStatistic
 
 __all__ = ['Accuracy',
            'PrecisionRecallF1score',
            'Precision',
            'Recall',
            'F1score',
            'ConfusionMatrix',
            'PrecisionRecallCurve',
            'AveragePrecision',
            'MeanAveragePrecision',
            'MeanIoU',
+           'BboxConfusionMatrix',
            'CountStatistic',
            'HistogramStatistic']
```

## gaea_operator/metric/operator/image/__init__.py

```diff
@@ -9,11 +9,12 @@
 from .accuracy import Accuracy
 from .precision_recall_f1score import PrecisionRecallF1score, Precision, Recall, F1score
 from .confusion_matrix import ConfusionMatrix
 from .precision_recall_curve import PrecisionRecallCurve
 from .average_precision import AveragePrecision
 from .mean_ap import MeanAveragePrecision
 from .mean_iou import MeanIoU
+from .bbox_confusion_matrix import BboxConfusionMatrix
 
 
 __all__ = ['Accuracy', 'PrecisionRecallF1score', 'Precision', 'Recall', 'F1score', 'ConfusionMatrix',
-           'PrecisionRecallCurve', 'AveragePrecision', 'MeanAveragePrecision', 'MeanIoU']
+           'PrecisionRecallCurve', 'AveragePrecision', 'MeanAveragePrecision', 'MeanIoU', 'BboxConfusionMatrix']
```

## gaea_operator/metric/operator/image/mean_ap.py

```diff
@@ -155,15 +155,14 @@
         重置eval_imgs_all
         """
         K = len(self.cat_ids)
         A = len(self.params.areaRng)
         self.eval_imgs_all = create_nd_list((K, A))
         self.eval = {}
         self.cur_dtid = 0
-        self.confusion_matrix = {}
 
     def _parse_dt_gt(self, predictions, groundths):
         """解析当前batch产出的预测结果
 
         Args:
             predictions (list): _description_
 
@@ -175,20 +174,21 @@
         self._gts = defaultdict(list)
 
         gts = copy.deepcopy(groundths)
         for gt in gts:
             if gt["image_id"] not in img_ids:
                 img_ids.add(gt["image_id"])
 
-            if self.params.iouType == "segm":
-                gt["area"] = mask_utils.area(gt['segmentation'])
-            else:
-                gt["area"] = gt['bbox'][2] * gt['bbox'][3]
+            if 'bbox' in gt:
+                if self.params.iouType == "segm":
+                    gt["area"] = mask_utils.area(gt['segmentation'])
+                else:
+                    gt["area"] = gt['bbox'][2] * gt['bbox'][3]
 
-            self._gts[(gt['image_id'], gt['category_id'])].append(gt)
+                self._gts[(gt['image_id'], gt['category_id'])].append(gt)
 
         for pred in predictions:
             if pred["image_id"] not in img_ids:
                 img_ids.add(pred["image_id"])
 
             if self.params.iouType == "segm":
                 pred["area"] = mask_utils.area(pred['segmentation'])
@@ -284,22 +284,14 @@
                         fp = np.array(fp)
                         nd = len(tp)
                         rc = tp / npig
                         pr = tp / (fp + tp + np.spacing(1))
                         q = np.zeros((R,))
                         ss = np.zeros((R,))
 
-                        if a == 0 and max_det == m_list[-1] and t == 0:
-                            raw = np.zeros(len(self.cat_ids))
-                            if nd:
-                                raw[k] = tp[-1]
-                            else:
-                                raw[k] = 0
-                            self.confusion_matrix[k_list2catId[k]] = raw.tolist()
-
                         if nd:
                             recall[t, k, a, m] = rc[-1]
                         else:
                             recall[t, k, a, m] = 0
 
                         # numpy is slow without cython optimization for accessing elements
                         # use python array gets significant speed improvement
@@ -541,16 +533,15 @@
         _results['bbox'] = self.coco_eval_bbox.eval_imgs_all
         _results['segm'] = self.coco_eval_segm.eval_imgs_all
 
         eval_results = {'bbox': [],
                         'segm': [],
                         'bbox_results_per_label': [],
                         'segm_results_per_label': [],
-                        'pr_curve': [],
-                        'confusion_matrix': {}}
+                        'pr_curve': []}
 
         if 'bbox' in _results:
             self.coco_eval_bbox.eval_imgs_all = _results['bbox']
             self.coco_eval_bbox.accumulate_rank()
             self.coco_eval_bbox.summarize()
 
         if self.segm:
@@ -568,15 +559,14 @@
                     self.coco_eval_bbox.eval['precision'], cate_names, 'bbox')
                 results_per_category = self._compute_per_cat_metrics(self.coco_eval_bbox.params,
                                                                      self.coco_eval_bbox.eval["precision"],
                                                                      self.coco_eval_bbox.eval["recall"])
                 eval_results['bbox_results_per_label'] = results_per_category
                 eval_results['pr_curve'] = self._compute_pr_curve(self.coco_eval_bbox.params,
                                                                   self.coco_eval_bbox.eval["precision"])
-                eval_results['confusion_matrix'] = self.coco_eval_bbox.confusion_matrix
 
             if self.segm:
                 self._compute_ap_pr(
                     self.coco_eval_segm.eval['precision'], cate_names, 'segm')
                 results_per_category = self._compute_per_cat_metrics(self.coco_eval_segm.params,
                                                                      self.coco_eval_segm.eval["precision"],
                                                                      self.coco_eval_segm.eval["recall"])
```

## gaea_operator/metric/types/metric.py

```diff
@@ -16,15 +16,15 @@
 ACCURACY_METRIC_NAME = "ACC"
 BOUNDING_BOX_LABEL_METRIC_NAME = "boundingBoxLabelMetric"
 BOUNDING_BOX_MEAN_AVERAGE_PRECISION_METRIC_NAME = "boundingBoxMeanAveragePrecision"
 BOUNDING_BOX_MEAN_AVERAGE_RECALL_METRIC_NAME = "boundingBoxMeanAverageRecall"
 BOUNDING_BOX_LABEL_AVERAGE_PRECISION_METRIC_NAME = "boundingBoxLabelAveragePrecision"
 CONFUSION_MATRIX_METRIC_NAME = "confusionMatrix"
 CLASSIFICATION_ACCURACY_METRIC_NAME = "accuracy"
-CLASSIFICATION_LABEL_PRECISION_METRIC_NAME = "LabelPrecision"
+CLASSIFICATION_LABEL_PRECISION_METRIC_NAME = "labelPrecision"
 SEMANTIC_SEGMENTATION_MIOU_METRIC_NAME = "meanIntersectionOverUnionMetric"
 SEMANTIC_SEGMENTATION_LABEL_IOU_METRIC_NAME = "labelIntersectionOverUnionMetric"
 LABEL_STATISTIC_METRIC = "labelStatisticMetric"
 ANNOTATION_CONFIDENCE_STATISTIC_METRIC = "annotationConfidenceStatisticMetric"
 ANNOTATION_AREA_STATISTIC_METRIC = "annotationAreaStatisticMetric"
 ANNOTATION_HEIGHT_STATISTIC_METRIC = "annotationHeightStatisticMetric"
 ANNOTATION_WIDTH_STATISTIC_METRIC = "annotationWidthStatisticMetric"
```

## gaea_operator/utils/accelerator.py

```diff
@@ -83,21 +83,22 @@
                         "/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin"
             }
 
     def suggest_flavours(self):
         """
         Suggest flavours
         """
-        flavour_list = ['c4m16gpu1',
-                        'c8m32gpu1',
-                        'c8m32gpu2',
-                        'c16m64gpu2',
-                        'c16m32gpu4',
-                        'c16m64gpu4',
-                        'c32m96gpu4']
+        flavour_list = [{"name": "c4m16gpu1", "display_name": "CPU: 4核 内存: 16Gi GPU: 1卡"},
+                        {"name": "c8m32gpu1", "display_name": "CPU: 8核 内存: 32Gi GPU: 1卡"},
+                        {"name": "c8m32gpu2", "display_name": "CPU: 8核 内存: 32Gi GPU: 2卡"},
+                        {"name": "c16m64gpu2", "display_name": "CPU: 16核 内存: 64Gi GPU: 2卡"},
+                        {"name": "c16m32gpu4", "display_name": "CPU: 16核 内存: 32Gi GPU: 4卡"},
+                        {"name": "c16m64gpu4", "display_name": "CPU: 16核 内存: 64Gi GPU: 4卡"},
+                        {"name": "c32m96gpu4", "display_name": "CPU: 32核 内存: 96Gi GPU: 4卡"}]
+
         return flavour_list
 
     def suggest_model_server_parameters(self):
         """
         Suggest model server parameters
         """
         resource = {"accelerator": self.name,
@@ -135,15 +136,15 @@
                 "XTCL_L3_SIZE": "16776192"
             }
 
     def suggest_flavours(self):
         """
         Suggest flavours
         """
-        flavour_list = ['c4m16xpu1']
+        flavour_list = [{"name": "c4m16xpu1", "display_name": "CPU: 4核 内存: 16Gi XPU: 1卡"}]
         return flavour_list
 
     def suggest_model_server_parameters(self):
         """
         Suggest model server parameters
         """
```

### encoding

```diff
@@ -1 +1 @@
-us-ascii
+utf-8
```

## Comparing `gaea_operator-1.2.0.7.data/data/classify.config/modify_train_parameter.py` & `gaea_operator-1.2.0.8.data/data/classify.config/modify_train_parameter.py`

 * *Files identical despite different names*

## Comparing `gaea_operator-1.2.0.7.data/data/classify.config/parameter.yaml` & `gaea_operator-1.2.0.8.data/data/classify.config/parameter.yaml`

 * *Files identical despite different names*

## Comparing `gaea_operator-1.2.0.7.data/data/ocrnet.config/modify_train_parameter.py` & `gaea_operator-1.2.0.8.data/data/ocrnet.config/modify_train_parameter.py`

 * *Files identical despite different names*

## Comparing `gaea_operator-1.2.0.7.data/data/ocrnet.config/parameter.yaml` & `gaea_operator-1.2.0.8.data/data/ocrnet.config/parameter.yaml`

 * *Files identical despite different names*

## Comparing `gaea_operator-1.2.0.7.data/data/ppyoloe_plus.config/modify_train_parameter.py` & `gaea_operator-1.2.0.8.data/data/ppyoloe_plus.config/modify_train_parameter.py`

 * *Files identical despite different names*

## Comparing `gaea_operator-1.2.0.7.data/data/ppyoloe_plus.config/parameter.yaml` & `gaea_operator-1.2.0.8.data/data/ppyoloe_plus.config/parameter.yaml`

 * *Files identical despite different names*

## Comparing `gaea_operator-1.2.0.7.data/data/ppyoloe_plus.config/parameter_c.yaml` & `gaea_operator-1.2.0.8.data/data/ppyoloe_plus.config/parameter_c.yaml`

 * *Files identical despite different names*

## Comparing `gaea_operator-1.2.0.7.data/data/schema/object_detection.yaml` & `gaea_operator-1.2.0.8.data/data/schema/object_detection.yaml`

 * *Files identical despite different names*

## Comparing `gaea_operator-1.2.0.7.dist-info/METADATA` & `gaea_operator-1.2.0.8.dist-info/METADATA`

 * *Files 0% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: gaea-operator
-Version: 1.2.0.7
+Version: 1.2.0.8
 Summary: A common operator library to help with training neural networks.
 Home-page: https://console.cloud.baidu-int.com/devops/icode/repos/baidu/mlops/gaea-operator/tree/master
 Author: liuyawen03
 Author-email: liuyawen03@baidu.com
 License: MIT
 Classifier: Programming Language :: Python
 Classifier: Programming Language :: Python :: 3
```

## Comparing `gaea_operator-1.2.0.7.dist-info/RECORD` & `gaea_operator-1.2.0.8.dist-info/RECORD`

 * *Files 4% similar despite different names*

```diff
@@ -12,15 +12,15 @@
 gaea_operator/components/train/ocrnet.py,sha256=lyoEWAO52qTw9_BkRnaUPJgtwFlIoPmuvx7LGGZ9kPU,7555
 gaea_operator/components/train/ppyoloe_plus.py,sha256=pJ7XuhRhpYQnL1IRkwzxrtWYI8-EgS8LnwZY6a9w0XU,8365
 gaea_operator/components/train/resnet.py,sha256=1AsZtSTZyCA965Dasw9Ti9VHK_55mO1BRSyBE7MAHNc,7390
 gaea_operator/components/transform/__init__.py,sha256=I_nhvM_IU3swPZsE4m9lKQj50PABhRHZTVkiDjYZK5s,131
 gaea_operator/components/transform/ocrnet.py,sha256=k9i3hja0zXpudX2vxr5V7bAUeB6qT-wgWsZgbg8FKGM,6338
 gaea_operator/components/transform/ppyoloe_plus.py,sha256=WzwLtmTyvhd6iINlmXoh1zEX20RQahB2v9qZT3PsmU0,6078
 gaea_operator/components/transform/resnet.py,sha256=-FHg9_M5Sdt46U6HxfjSqHOUFA8jc6c0O6qgg7fk7aM,6214
-gaea_operator/components/transform_eval/__init__.py,sha256=tdT6-SVn3WI4TMpSTEjVhGJFu43_954ZRTt2snqBxKA,3559
+gaea_operator/components/transform_eval/__init__.py,sha256=E_9U6xvDbG0fNd4RTroTO5VdOcc4jPVEGUzvjSm6hGA,3558
 gaea_operator/components/transform_eval/transform_eval.py,sha256=KWuX1Rd9MzBORTnjjsgD2M3XOt4w4PGA8bQKwn4PcME,7658
 gaea_operator/config/__init__.py,sha256=b283tp9PPcPViZMKzZPXa95bSNQQQHSHoP724eR8MdI,505
 gaea_operator/config/config.py,sha256=npxGcoNgTIU-pKnWpgqZBWLfWZm3GiYNTqhY3zeG_p0,4883
 gaea_operator/config/generate_transform_config.py,sha256=1IYQEGdgQNr0GG4h6jzS1qpH2WVkIuq-EHimJ-rrkck,14048
 gaea_operator/config/modify_package_files.py,sha256=iZAmxnNPdH0cHuEFJUTnzf0rM54rPFfyI7ZDJaUe1zU,14835
 gaea_operator/config/update_parse.py,sha256=JrqELK2dgIWCrtVz8gI6A6rH_5QbqZOHDNCDujnMqxs,3642
 gaea_operator/config/update_pbtxt.py,sha256=w3A5CRbnK1B4vKyUA8Qk2EDWLAqatM3ZkOw9Jxj1v9Q,16721
@@ -43,61 +43,62 @@
 gaea_operator/dataset/cityscape_dataset.py,sha256=yFZTiaME6G2qLgn-Uu42rrHnd6lwE0lD9msvIIJfVA8,3949
 gaea_operator/dataset/coco_dataset.py,sha256=C3-EQyHG9sRlrzGVEWJ-4D8-wz6bArhx5yF6w9bc7vA,5061
 gaea_operator/dataset/dataset.py,sha256=m7GCRjhTl59PdrL6T3dXpk_JJPB0RXo0jmnfVW2bYC0,4969
 gaea_operator/dataset/imagenet_dataset.py,sha256=MakeE84BEv-2bylfLkiGVFKd10JHa312gJQRIUt4zQ8,4306
 gaea_operator/metric/__init__.py,sha256=fk0G_Cw3od-yzlYq5l48xDslTmqLFddrWoXOi3xqI48,584
 gaea_operator/metric/metric.py,sha256=D_tp55AefLCqO0Ny0Zqt04ynn0rgRUjH9mJMN2GI9nQ,5613
 gaea_operator/metric/analysis/__init__.py,sha256=kEv9_MuQOFC83fCprxY19T7omFNXa9dAuxstXlsEsX8,433
-gaea_operator/metric/analysis/eval_metric_analysis.py,sha256=V8sTAs0LToO2oKdj2C08NIovP2RBrT0iNTU7KZNC8-E,14048
-gaea_operator/metric/analysis/inference_metric_analysis.py,sha256=aVFvGPr6i3tEn0mc1_KRQMpXLJ-cpxyGTO6po6NXl2I,5987
-gaea_operator/metric/analysis/label_statistics_metric_analysis.py,sha256=x7QlkLBWxIWkiv8ufVKFdrawUY-PXmje4LSbx6pTknY,8902
-gaea_operator/metric/operator/__init__.py,sha256=WwFRIAWpgRwzlu1O5rRQIqevbrDtQ3kB1yE6q0aWSDE,737
+gaea_operator/metric/analysis/eval_metric_analysis.py,sha256=EBJsZexOOQPIUXCHLmth_Yd7qeUkdAUvBr0C2NCOJ5c,15383
+gaea_operator/metric/analysis/inference_metric_analysis.py,sha256=yw0fDGdFGnUi-PgrONuRzTdqNDwgPww1XzBLrqsMiHE,6532
+gaea_operator/metric/analysis/label_statistics_metric_analysis.py,sha256=xS2VB007iEGD-5QKP66an_POy_KN-TmnuVjsjK9jrTw,11301
+gaea_operator/metric/operator/__init__.py,sha256=Tz9wUArWR7NZvW1X9OwIGn7yTIELiwFFYszRXhQnAyY,792
 gaea_operator/metric/operator/check.py,sha256=CTaAvD4VDpllUp3d7_1HD-HP_b3beuh-HyMwM2V6u4o,3195
 gaea_operator/metric/operator/metric.py,sha256=ia3NY6twXmFgr_ULfaudIcbmIqyJJwC51pakJdpvRhc,1923
-gaea_operator/metric/operator/image/__init__.py,sha256=Ou9KSCFoIy2h3DIeNBZlHn4iy-hGibzY-geg1VwCX_o,701
+gaea_operator/metric/operator/image/__init__.py,sha256=iw6-w66SbPp5uLPizSWLJU4qumZI3kKGR_GcVrWrHpc,779
 gaea_operator/metric/operator/image/accuracy.py,sha256=O-0m0zkPmlEzp4Hr3fI6oYmFdBvxtZoXP9Wfma4kgD8,6960
 gaea_operator/metric/operator/image/average_precision.py,sha256=WMZZk1de78k23OYZ8kDzV9ndCJwpysh3GNSmK4XZ9lc,2571
+gaea_operator/metric/operator/image/bbox_confusion_matrix.py,sha256=ru8MW9RN-58SMKIOxYJBWszW3PCw5YZtMvxqP5PWDXI,5264
 gaea_operator/metric/operator/image/confusion_matrix.py,sha256=FnTZ2ZL1aJK70YQFHik1XBuRFEYWRPwZwr5leVm5UYo,3939
-gaea_operator/metric/operator/image/mean_ap.py,sha256=Clfd-Ai-83hlAXENeiixaxrOe3Ig27fuCujj9GOfmnA,21177
+gaea_operator/metric/operator/image/mean_ap.py,sha256=hJXEEbrI6YOr3vpJe3ZisJ4qDGztncBn5bsEfHTjlOU,20678
 gaea_operator/metric/operator/image/mean_iou.py,sha256=ZMyQrwYMNS0sYnNHY24UWHWuhVp70b74yuQg-qZ5gRU,6128
 gaea_operator/metric/operator/image/precision_recall_curve.py,sha256=-Roa0GhfeZ0eAFpFSnhCisCXuImgB6NsKnDvtclpZCw,19509
 gaea_operator/metric/operator/image/precision_recall_f1score.py,sha256=O_NnxZVHCg1kQZOzrkN6iY8pWPv84xKL0we9R1BW9aM,11271
 gaea_operator/metric/operator/tabular/__init__.py,sha256=_ISQwafNoF9A9iIU1Sa2Qp1ftiOBGnKEVyKzEpPbCjA,289
 gaea_operator/metric/operator/tabular/count_statistic.py,sha256=07zCGsGggCmsQOFdtMAdu-yusHRVAeBMjguAvzKIFD4,1207
 gaea_operator/metric/operator/tabular/histogram_statistic.py,sha256=8UwsjxAMG-_ZYu6mU6a4W0t7CsygnORy7syk6-ze5Xk,2185
 gaea_operator/metric/schema/object_detection.yaml,sha256=2V6AJBVa1nAE9FAosyz4z4Qv0ebw1IumYoRPUWo3Ebg,4864
 gaea_operator/metric/types/__init__.py,sha256=x5whaLpvnYR6XL2VB8IbYJ12jtYW7_zUnWks_JZY1A8,131
 gaea_operator/metric/types/image_classification_metric.py,sha256=Q-XVRRogS43yhuN0MHQY6viu-k9_r6ADK_Df2tBjPkU,1173
-gaea_operator/metric/types/metric.py,sha256=cG9oavFI6m1BoPXgP2KR5At7hCnau14fsJUqYRa8AKM,4874
+gaea_operator/metric/types/metric.py,sha256=H1KHU_Kf3yxXd4pvrxY2d75tBNkQ0vEQ526A6tg3AnI,4874
 gaea_operator/metric/types/object_detection_metric.py,sha256=fS5aJZ8lHxRAcs69bfgVlvRijsbAAjuWSg2ZtuVtKA0,2362
 gaea_operator/metric/types/semantic_segmentation_metric.py,sha256=RVOUp2x8QGKwf3EepvBR-yaLvEj0OF6uM0aC0Ah-ASQ,1244
 gaea_operator/model/__init__.py,sha256=EssP2HXBMWO-4iXPbWjscBrXxSojJBOOHV3p-ioV6tA,214
 gaea_operator/model/model.py,sha256=pNswhABsGB5HHeExA4fOHH4ob2uRPqs97sCzRGPQwIo,1436
 gaea_operator/trainer/__init__.py,sha256=Kpisv4LZyJQy6vEce-8g3HS8bo8y6rwk8K3pEaF0na0,181
 gaea_operator/trainer/trainer.py,sha256=UTlxVZ871jS3z0qPav9LJqf2NZMvsAqHNQPzVoJEuOA,4979
 gaea_operator/transform/__init__.py,sha256=1NtMabt2_F9fVeLuAM7g3i0yIac_4RP0lHMZzdyDDcY,187
 gaea_operator/transform/cvt_copy_model.py,sha256=jSWWgt2RT9ULPLNyOxypmpNuQ1kWH0gw2XNe6OLE7Sw,3307
 gaea_operator/transform/transform.py,sha256=kDZ4m4QUPbuDYSwT6lKFH7T0GEADNL3f6T-L4IUjG0g,776
 gaea_operator/utils/__init__.py,sha256=DmxN4SMbqaCs_ZHTJBF9eMitaXKLIi1Qm6TKHT_NY0Q,1788
-gaea_operator/utils/accelerator.py,sha256=eR5pbm_fC7Q-Z_N8pAH9Vz4pkkNNWUeoH_K3B17R1Ik,5053
+gaea_operator/utils/accelerator.py,sha256=sjnCY5vJKnWATKIulHsO3t6ifdnHbtBBDzbtkg7KR7E,5554
 gaea_operator/utils/compress.py,sha256=iVH0usAYQidWYT2Mo8a6uJa5uGl8knwSn64CYmfkIss,2717
 gaea_operator/utils/consts.py,sha256=0TsyISenFn_x8eRNIH1fdXPLw8zSac-IAfiCxKbhySw,426
 gaea_operator/utils/file.py,sha256=9g9fFq8aw4t0I8D3wkN9Bao3tfaN3X3itZmO4LF6MsU,1948
 gaea_operator/utils/import_module.py,sha256=W1mKFqBClRsYm9MNqParN-03PUFIwgMJJAgSAvD9m38,1533
 gaea_operator/utils/model_template.py,sha256=n9vvjumL9wtqTHmyvLsdZdewyH1sksqGY6APmnIGG7Y,6613
 gaea_operator/utils/registry.py,sha256=QchfsCrwhk3i8gmtS16PAF4029TcdOdEeWUdo1ruAps,1680
 gaea_operator/utils/tensor.py,sha256=BLnnyKz79hOqZy-L7IeA4ffDX5DoWP9NvLzStdI6C8w,1000
 gaea_operator/utils/time.py,sha256=xNKc-rzCCwhh-hNlNO05J_TA6rCMKMepuZ3qzvcScLs,301
-gaea_operator-1.2.0.7.data/data/classify.config/modify_train_parameter.py,sha256=gjV6zhJQbQajBHyMa1YsNyJS4cfXJCWFXB7wf1z7jSQ,11390
-gaea_operator-1.2.0.7.data/data/classify.config/parameter.yaml,sha256=aojj7ToIuE1KgAdxVtegP6fZqHylzdTUGMFoUwMq3h8,2315
-gaea_operator-1.2.0.7.data/data/ocrnet.config/__init__.py,sha256=lX4deGvIgAQ1fTcskBUDqRfnOlOabgQjZXGwOJCVCkU,130
-gaea_operator-1.2.0.7.data/data/ocrnet.config/modify_train_parameter.py,sha256=LLPXaq-NTmJwGyZEoqhVYWjiiHF43Yr8WNLwp9TADiA,8814
-gaea_operator-1.2.0.7.data/data/ocrnet.config/parameter.yaml,sha256=CbogpeuW_OZJLgF0AbxsFjFJzZ-_RF3s9NCnGojGB9o,1467
-gaea_operator-1.2.0.7.data/data/ppyoloe_plus.config/__init__.py,sha256=lX4deGvIgAQ1fTcskBUDqRfnOlOabgQjZXGwOJCVCkU,130
-gaea_operator-1.2.0.7.data/data/ppyoloe_plus.config/modify_train_parameter.py,sha256=BePbG16yrxAJiwctUbc0s1VtKDDThsDtylndcIO8WPk,12621
-gaea_operator-1.2.0.7.data/data/ppyoloe_plus.config/parameter.yaml,sha256=pDZpMs6fsuVqwGIEv0T1oaasF3FQW_Rs0sneuoN54I0,4582
-gaea_operator-1.2.0.7.data/data/ppyoloe_plus.config/parameter_c.yaml,sha256=KVxZIotf24fk_SAI1v-CHNMC2ouG_lpMY0l_CtSXoRM,4666
-gaea_operator-1.2.0.7.data/data/schema/object_detection.yaml,sha256=2V6AJBVa1nAE9FAosyz4z4Qv0ebw1IumYoRPUWo3Ebg,4864
-gaea_operator-1.2.0.7.dist-info/METADATA,sha256=YRNhY2h1djaOJrg8Ys8BpaKE9bmF44gu5hVwAWGK5Ls,2091
-gaea_operator-1.2.0.7.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
-gaea_operator-1.2.0.7.dist-info/top_level.txt,sha256=1-ONMzqexKnQ2qOurelrROodwfO1B8jTzpzbERvNycY,14
-gaea_operator-1.2.0.7.dist-info/RECORD,,
+gaea_operator-1.2.0.8.data/data/classify.config/modify_train_parameter.py,sha256=gjV6zhJQbQajBHyMa1YsNyJS4cfXJCWFXB7wf1z7jSQ,11390
+gaea_operator-1.2.0.8.data/data/classify.config/parameter.yaml,sha256=aojj7ToIuE1KgAdxVtegP6fZqHylzdTUGMFoUwMq3h8,2315
+gaea_operator-1.2.0.8.data/data/ocrnet.config/__init__.py,sha256=lX4deGvIgAQ1fTcskBUDqRfnOlOabgQjZXGwOJCVCkU,130
+gaea_operator-1.2.0.8.data/data/ocrnet.config/modify_train_parameter.py,sha256=LLPXaq-NTmJwGyZEoqhVYWjiiHF43Yr8WNLwp9TADiA,8814
+gaea_operator-1.2.0.8.data/data/ocrnet.config/parameter.yaml,sha256=CbogpeuW_OZJLgF0AbxsFjFJzZ-_RF3s9NCnGojGB9o,1467
+gaea_operator-1.2.0.8.data/data/ppyoloe_plus.config/__init__.py,sha256=lX4deGvIgAQ1fTcskBUDqRfnOlOabgQjZXGwOJCVCkU,130
+gaea_operator-1.2.0.8.data/data/ppyoloe_plus.config/modify_train_parameter.py,sha256=BePbG16yrxAJiwctUbc0s1VtKDDThsDtylndcIO8WPk,12621
+gaea_operator-1.2.0.8.data/data/ppyoloe_plus.config/parameter.yaml,sha256=pDZpMs6fsuVqwGIEv0T1oaasF3FQW_Rs0sneuoN54I0,4582
+gaea_operator-1.2.0.8.data/data/ppyoloe_plus.config/parameter_c.yaml,sha256=KVxZIotf24fk_SAI1v-CHNMC2ouG_lpMY0l_CtSXoRM,4666
+gaea_operator-1.2.0.8.data/data/schema/object_detection.yaml,sha256=2V6AJBVa1nAE9FAosyz4z4Qv0ebw1IumYoRPUWo3Ebg,4864
+gaea_operator-1.2.0.8.dist-info/METADATA,sha256=7rdjJK9qGvbVb0Eyi59udSzldmIivb5sVsylyfUrAQU,2091
+gaea_operator-1.2.0.8.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
+gaea_operator-1.2.0.8.dist-info/top_level.txt,sha256=1-ONMzqexKnQ2qOurelrROodwfO1B8jTzpzbERvNycY,14
+gaea_operator-1.2.0.8.dist-info/RECORD,,
```

